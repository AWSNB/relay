{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Sentry Relay is a standalone service that allows you to scrub personal information and improve event response time. It acts as a middle layer between your application and Sentry.io. Relay is still work in progress. The default Relay mode is not supported by Sentry, so Relay has to be switched into proxy or static mode. See Relay Modes for more information. Use Cases for Relay Relay was designed with a few usage scenarios in mind. Scrubbing Personally Identifiable Information (PII) Sentry allows to scrub PII in two places: in the SDK before sending the event, and upon arrival on Sentry's infrastructure. Relay adds a third option that allows to scrub data in a central place before sending it to Sentry. To choose the right place for data scrubbing, consider: If you prefer to configure data scrubbing in a central place, you can let Sentry handle data scrubbing. Upon arrival, Sentry immediatly applies server-side scrubbing and guaratees that personal information is never stored. If you cannot send PII outside your infrastructure but you still prefer to configure data scrubbing in one centralized place, run Relay and configure your SDKs to send events there. Relay uses the privacy settings configured in Sentry, and scrubs PII before forwarding data to Sentry. For the most strict data privacy requirements, you can configure SDKs to scrub PII using the before_send hooks , which prevents data from being collected on the device. This may require you to replicate the same logic across your applications and could lead to a performance impact. Improved Response Time Relay is designed to respond very quickly to requests. Having Relay installed close to your infrastructure will further improve the response when sending events. This can particularly reduce the roundtrip time in remote locations. Enterprise Domain Name By default, SDKs need to be configured with a DSN that points to sentry.io . If you need to restrict all HTTP communication to a custom domain name, Relay can act as an opaque proxy that reliably forwards events to Sentry. Getting Started In this section we will create a simple setup using the default settings. Check the Configuration Options page for a detail discussion of various operating scenarious for Relay. The Relay server is called relay . Binaries can be downloaded from GitHub Releases and a Docker image is provided on DockerHub . Initializing Configuration In order to create the initial configuration, Relay provides the relay config init command. The command puts configuration files in the .relay folder under the current working directory: \u276f ./relay config init Initializing relay in /<current_directory>/.relay Do you want to create a new config?: > Yes, create default config Yes, create custom config No, abort Selecting the default configuration will create a minimal configuration file. Alternatively, you can choose to override the default settings, by selecting *\"create custom config\" . This allows you to customize the following basic parameters: The mode setting configures the major mode in which Relay operates. For more information on available relay modes, refer to Relay Modes . The upstream setting configures the server to which Relay will forward the events (by default the main sentry.io URL). The port and host settings configure the TCP port at which Relay will listen to. This is the address to which SDKs send events. The tls settings configure TLS support (HTTPS support), used for the cases where the communication between the SDK and Relay needs to be secured. Settings are placed in .relay/config.yml . Note that all configuration values are optional and default to these settings: --- relay : mode : managed upstream : \"https://sentry.io/\" host : 127.0.0.1 port : 3000 tls_port : ~ tls_identity_path : ~ tls_identity_password : ~ All configurations are explained in detail in the section Configuration Options . Credentials Besides config.yml , the init command has also created a credentials file credentials.json in the same .relay directory. This file contains the a public and private key used by Relay to authenticate with the upstream server. As such, it is important that this file should be adequatly protected from modification or viewing by unauthorized entities . Here's an example of the contents of a typical credentials file: { \"secret_key\" : \"5gkTAfwOrJ0lMy9aOAOmHKO1k6gd8ApYkAInmg5VfWk\" , \"public_key\" : \"fQzvlvqLM2pJwLDwM_sXD2Lk5swzx-Oml4WhsOquon4\" , \"id\" : \"cde0d72e-0c4e-4550-a934-c1867d8a177c\" } You will be using the public_key to register your Relay with the upstream server when running it in managed mode. Registering Relay with Sentry This option is not available on Sentry.io. Instead, configure Relay in proxy or static mode and skip this step. To operate in managed mode, Relay pulls configuration for PII stripping, filtering, and rate limiting from your organization and project settings at Sentry. Since these settings may contain sensitive information, their access is restricted by Sentry and requires authorization. In order to register Relay with Sentry, get the contents of the public key, either by inspecting the credentials.json file or by running: \u276f ./relay credentials show Credentials: relay id: 8cd24a0e-384d-4052-9010-68a21392b33c public key: nDJl79SbEYH9-8NEJAI7ezrgYfolPW3Bnkg00k1zOfA After copying the public key, go to the organization settings in Sentry by clicking on Settings in the main navigation on the left, then go to Relays . Click New Relay Key to add the key and save it: Now your Relay is registered with Sentry and ready to send messages. See Configuration Options page to learn more about further Relay configuration options. Running Relay Once you have registered your Relay with Sentry, you are ready to run your Relay: \u276f relay run INFO relay::setup > launching relay from config folder .relay INFO relay::setup > relay mode: managed INFO relay::setup > relay id: f2119bc9-9a9b-4531-826b-24e9794902f2 INFO relay::setup > public key: QPBITKKtKUuEZGGbPke8iufEXAcVrEv6nmWrkRtc3l8 ... DEBUG relay::server::upstream > relay successfully registered with upstream If you moved your config folder somewhere else (e.g. for security reasons), you can use the --config option to specify the location: \u276f relay run --config ./my/custom/relay_folder/ Running in Docker As an alternative to directly running the Relay binary, Sentry also provides a Docker image that can be used to run Relay. It can be found on DockerHub . Similar to directly running the relay binary, running the docker image needs a directory in which it can find the configuration and credentials files ( config.yml and credentials.json ). Providing the configuration directory can be done with the standard mechanisms offered by docker, either by mounting docker volumes or by building a new container and copying the files in. For example, you can start the latest version of relay as follows: \u276f docker run -v $( pwd ) /configs/:/work/.relay/ getsentry/relay run This example command assumes that Relay's configuration ( config.yml and credentials.json ) are stored in ./configs/ directory on the host machine. Sending a Test Event Once Relay is running and authenticated with Sentry, it is time to send a test event. Get the DSN of your project by navigating to your Project Settings > Client Keys (DSN) . From the Client Keys page, get the DSN, which looks something like: https://12345abcdb1e4c123490ecec89c1f199@o1.ingest.sentry.io/2244 Next, replace parts of the DSN to match the address at which Relay is reachable. For instance, if Relay listens at http://localhost:3000 , change the protocol and host of the DSN to: http://12345abcdb1e4c123490ecec89c1f199@localhost:3000/2244 Use the new DSN in your SDK configuration. To test this, you can send a message with sentry-cli : \u276f export SENTRY_DSN = 'http://12345abcdb1e4c123490ecec89c1f199@127.0.0.1:3000/2244' \u276f sentry-cli send-event -m 'A test event' After a few seconds, the event should appear in the issues stream in your project.","title":"Introduction"},{"location":"#introduction","text":"Sentry Relay is a standalone service that allows you to scrub personal information and improve event response time. It acts as a middle layer between your application and Sentry.io. Relay is still work in progress. The default Relay mode is not supported by Sentry, so Relay has to be switched into proxy or static mode. See Relay Modes for more information.","title":"Introduction"},{"location":"#use-cases-for-relay","text":"Relay was designed with a few usage scenarios in mind.","title":"Use Cases for Relay"},{"location":"#scrubbing-personally-identifiable-information-pii","text":"Sentry allows to scrub PII in two places: in the SDK before sending the event, and upon arrival on Sentry's infrastructure. Relay adds a third option that allows to scrub data in a central place before sending it to Sentry. To choose the right place for data scrubbing, consider: If you prefer to configure data scrubbing in a central place, you can let Sentry handle data scrubbing. Upon arrival, Sentry immediatly applies server-side scrubbing and guaratees that personal information is never stored. If you cannot send PII outside your infrastructure but you still prefer to configure data scrubbing in one centralized place, run Relay and configure your SDKs to send events there. Relay uses the privacy settings configured in Sentry, and scrubs PII before forwarding data to Sentry. For the most strict data privacy requirements, you can configure SDKs to scrub PII using the before_send hooks , which prevents data from being collected on the device. This may require you to replicate the same logic across your applications and could lead to a performance impact.","title":"Scrubbing Personally Identifiable Information (PII)"},{"location":"#improved-response-time","text":"Relay is designed to respond very quickly to requests. Having Relay installed close to your infrastructure will further improve the response when sending events. This can particularly reduce the roundtrip time in remote locations.","title":"Improved Response Time"},{"location":"#enterprise-domain-name","text":"By default, SDKs need to be configured with a DSN that points to sentry.io . If you need to restrict all HTTP communication to a custom domain name, Relay can act as an opaque proxy that reliably forwards events to Sentry.","title":"Enterprise Domain Name"},{"location":"#getting-started","text":"In this section we will create a simple setup using the default settings. Check the Configuration Options page for a detail discussion of various operating scenarious for Relay. The Relay server is called relay . Binaries can be downloaded from GitHub Releases and a Docker image is provided on DockerHub .","title":"Getting Started"},{"location":"#initializing-configuration","text":"In order to create the initial configuration, Relay provides the relay config init command. The command puts configuration files in the .relay folder under the current working directory: \u276f ./relay config init Initializing relay in /<current_directory>/.relay Do you want to create a new config?: > Yes, create default config Yes, create custom config No, abort Selecting the default configuration will create a minimal configuration file. Alternatively, you can choose to override the default settings, by selecting *\"create custom config\" . This allows you to customize the following basic parameters: The mode setting configures the major mode in which Relay operates. For more information on available relay modes, refer to Relay Modes . The upstream setting configures the server to which Relay will forward the events (by default the main sentry.io URL). The port and host settings configure the TCP port at which Relay will listen to. This is the address to which SDKs send events. The tls settings configure TLS support (HTTPS support), used for the cases where the communication between the SDK and Relay needs to be secured. Settings are placed in .relay/config.yml . Note that all configuration values are optional and default to these settings: --- relay : mode : managed upstream : \"https://sentry.io/\" host : 127.0.0.1 port : 3000 tls_port : ~ tls_identity_path : ~ tls_identity_password : ~ All configurations are explained in detail in the section Configuration Options .","title":"Initializing Configuration"},{"location":"#credentials","text":"Besides config.yml , the init command has also created a credentials file credentials.json in the same .relay directory. This file contains the a public and private key used by Relay to authenticate with the upstream server. As such, it is important that this file should be adequatly protected from modification or viewing by unauthorized entities . Here's an example of the contents of a typical credentials file: { \"secret_key\" : \"5gkTAfwOrJ0lMy9aOAOmHKO1k6gd8ApYkAInmg5VfWk\" , \"public_key\" : \"fQzvlvqLM2pJwLDwM_sXD2Lk5swzx-Oml4WhsOquon4\" , \"id\" : \"cde0d72e-0c4e-4550-a934-c1867d8a177c\" } You will be using the public_key to register your Relay with the upstream server when running it in managed mode.","title":"Credentials"},{"location":"#registering-relay-with-sentry","text":"This option is not available on Sentry.io. Instead, configure Relay in proxy or static mode and skip this step. To operate in managed mode, Relay pulls configuration for PII stripping, filtering, and rate limiting from your organization and project settings at Sentry. Since these settings may contain sensitive information, their access is restricted by Sentry and requires authorization. In order to register Relay with Sentry, get the contents of the public key, either by inspecting the credentials.json file or by running: \u276f ./relay credentials show Credentials: relay id: 8cd24a0e-384d-4052-9010-68a21392b33c public key: nDJl79SbEYH9-8NEJAI7ezrgYfolPW3Bnkg00k1zOfA After copying the public key, go to the organization settings in Sentry by clicking on Settings in the main navigation on the left, then go to Relays . Click New Relay Key to add the key and save it: Now your Relay is registered with Sentry and ready to send messages. See Configuration Options page to learn more about further Relay configuration options.","title":"Registering Relay with Sentry"},{"location":"#running-relay","text":"Once you have registered your Relay with Sentry, you are ready to run your Relay: \u276f relay run INFO relay::setup > launching relay from config folder .relay INFO relay::setup > relay mode: managed INFO relay::setup > relay id: f2119bc9-9a9b-4531-826b-24e9794902f2 INFO relay::setup > public key: QPBITKKtKUuEZGGbPke8iufEXAcVrEv6nmWrkRtc3l8 ... DEBUG relay::server::upstream > relay successfully registered with upstream If you moved your config folder somewhere else (e.g. for security reasons), you can use the --config option to specify the location: \u276f relay run --config ./my/custom/relay_folder/","title":"Running Relay"},{"location":"#running-in-docker","text":"As an alternative to directly running the Relay binary, Sentry also provides a Docker image that can be used to run Relay. It can be found on DockerHub . Similar to directly running the relay binary, running the docker image needs a directory in which it can find the configuration and credentials files ( config.yml and credentials.json ). Providing the configuration directory can be done with the standard mechanisms offered by docker, either by mounting docker volumes or by building a new container and copying the files in. For example, you can start the latest version of relay as follows: \u276f docker run -v $( pwd ) /configs/:/work/.relay/ getsentry/relay run This example command assumes that Relay's configuration ( config.yml and credentials.json ) are stored in ./configs/ directory on the host machine.","title":"Running in Docker"},{"location":"#sending-a-test-event","text":"Once Relay is running and authenticated with Sentry, it is time to send a test event. Get the DSN of your project by navigating to your Project Settings > Client Keys (DSN) . From the Client Keys page, get the DSN, which looks something like: https://12345abcdb1e4c123490ecec89c1f199@o1.ingest.sentry.io/2244 Next, replace parts of the DSN to match the address at which Relay is reachable. For instance, if Relay listens at http://localhost:3000 , change the protocol and host of the DSN to: http://12345abcdb1e4c123490ecec89c1f199@localhost:3000/2244 Use the new DSN in your SDK configuration. To test this, you can send a message with sentry-cli : \u276f export SENTRY_DSN = 'http://12345abcdb1e4c123490ecec89c1f199@127.0.0.1:3000/2244' \u276f sentry-cli send-event -m 'A test event' After a few seconds, the event should appear in the issues stream in your project.","title":"Sending a Test Event"},{"location":"architecture/","text":"Architecture This subsection contains internal docs that are useful for development and operation of Relay. Important Note : Relay is undergoing extensive internal restructuring. This includes: The introduction of Envelopes for event ingestion. Updated rate limits to handle items different from each other. Changes to the project configuration and fetching mechanism. Optimizations in the rate limiting fast path. Once these changes are completed, this document will be updated with new descriptions about event ingestion and the architecture.","title":"Architecture"},{"location":"architecture/#architecture","text":"This subsection contains internal docs that are useful for development and operation of Relay. Important Note : Relay is undergoing extensive internal restructuring. This includes: The introduction of Envelopes for event ingestion. Updated rate limits to handle items different from each other. Changes to the project configuration and fetching mechanism. Optimizations in the rate limiting fast path. Once these changes are completed, this document will be updated with new descriptions about event ingestion and the architecture.","title":"Architecture"},{"location":"architecture/actors/","text":"Actors This document describes how Relay works through the perspective of the system actors and the messages exchanged by them. TODO Short description about infrastructure (i.e. actix-web, actix, tokio, futures), note that we are using the old style Future trait, and actix 0.7.x . controller.rs events.rs The events.rs module contains functionality related to the processing of events. Raw events being sent to the system are first processed, and then sent to Sentry for saving. The module contains to actors: EventManager : an actor that receives all events, checks if the event should be processed (i.e. it is not filtered) and orchestrates all data needed for event processing. If the event should be processed it is passed to the EventProcessor . There is one EventManager in the system. EventProcessor : an CPU bound actor that receives all necessary project configuration and does the heavy lifting of processing the message (normalisation, PII stripping ...). There are multiple EventProcessor actors running in a thread pool. EventManager The EventManager is an actor running in the main system arbiter. The system arbiter is a asynchronous arbiter created when Relay starts. The upshot of this is that all processing done by the event manager should be extremly quick. It is ok to wait on I/O but no significant processing may be done in the EventManager . Once the EventManager had obtained the project state and had decided that the event should be processed the EventManager passes the event to the EventProcessor actors. TODO document all handlers EventProcessor The EventProcessor is an actor running in a SyncArbiter. There are multiple instances of the EventProcessor actor (roughly 1 per thread) ( TODO RaduW check that I'm not talking nonsense here.). The EventProcessor does the heavy lifting of event processing. The event processing does only synchronous work ( all the IO is handleed in the EventManager and all the needed state is passed to the EventProcessor ) Since all the work done by the event processor is the synchronous processing of an event there is only one type of message accepted by the EventProcessor actor: ProcessEvent The ProcessEvent handler prepares the event for ingestion. It normalizes the event, symbolicates its stack-trace and strips sensitive information (PPI stripping). TODO finish here keys.rs outcome.rs server.rs store.rs upstream.rs project.rs The project.rs module contains functionality related to the project state. Sentry events belong to projects and projects belong to organizations (Relay doesn't care at the moment about organizations). Projects serve to group the events (so that each Sentry customer can only see and deal with his/hers own events) and prescribe how messages are to be processed ( what should be filtered, which data inside the event should be anonymised (i.e PPI stripping), etc). All activities around obtaining, caching and refreshing the project state is handled in this module. The module contains two actors: Project : an actor that holds project data ProjectCache : an actor that holds references to Project actors. From a high level perspective one obtains a Project from the ProjectCache and then uses the Project in order to get 'project specific' information. Project The Project actor is responsible with decisions about how an event for a particular project should be handled. The project runs in an async arbiter ( I think it actully runs in the SystemArbiter TODO check ir that is true, or if it runs in another async arbiter). The system constructs an actor for each project used. The Project actor runs in an async context. The Project actor responds to the following message types: GetProjectId The GetProjectId handler returns the project_id (trivial functionality). GetProjectState The handler retuns the ProjectState , either directly (if it has a recent cached version) or by asking the ProjectCache to fetch it on its behalf. Pseudo Code if 'we have an up-to-date project state' return self . project_state if not self . receiver : # we don't have an already active request for the project state channel , receiver = 'create a channel and save its receiver' async : # ops that run at some time in the future project_state = await ProjectCache . send ( FetchProjectState ) channel . sender . push ( project_state ) # put the state on the channel when available channel = None # clenaup after we have pushed the ProjectState return future ( receiver ) # a Future that resolves with the ProjectState when available GetEventAction The handler answers the question: How should an event be handled? An event may be handled in one of three ways specified by the EventAction enum. pub enum EventAction { /// The event should be discarded. Discard ( DiscardReason ), /// The event should be discarded and the client should back off for some time. RetryAfter ( RateLimit ), /// The event should be processed and sent to upstream. Accept , } Pseudo Code if 'we have a cached rate limit value for the current event key' : return RetryAfter # the event is discarded without further processing if 'we have a recent project state' # Ask the ProjectState what to do with the msg return projectState . get_event_action ( event ) # No recent ProjectState, fetch it from the ProjectCache actor async : # ops that run at soem time in the future projectState = await ProjectCache . send ( FetchProjectState ) # return a future that will resolve when the project state becomes avaialble return future ( projectState . get_event_action ( event )) RateLimit The handler is used to update chached versions of project RateLimits. Pseudo Code if rate_limit . type not in self . rate_limit_cache self . rate_limit_cache . insert ( rate_limit ) # insert a new rate limit else if \"rate_limit expires sooner than the old cached value\" : self . rate_limit_cache . insert ( rate_limit ) # update old rate limit ProjectCache The ProjectCache actor is responsible for providing Project actors. The ProjectCache runs in an asynchronous context. There is only one instance of the ProjectCache in the system. The project runs in an async arbiter ( I think it actully runs in the SystemArbiter TODO check ir that is true, or if it runs in another async arbiter). The ProjectCache actor responds to the following messages: GetProject Retuns a Project actor for the required project. Pseudo Code if project_id not in self . project_cache : project = Project ( project_id ) project . start () self . project_cache [ project_id ] = project return self . project_cache [ porject_id ] FetchProjectState Registers the intention of a project to retrieve the project state. The FetchProjectState functionality logicaly belongs to the Project actor but it is handled by the ProjectCache in order to batch requests for the project state from multiple Project actors. A Project registers its desire to obtain its project state with the ProjectCache by sending the FetchProjectState and the ProjectCache batches all requests during a batching period and emits one request to the upstream (another Relay or the Sentry server) for all required project states. The handler checks if there is already a scheduled time for fetching project states and, if not, it schedules a delayed function that will do the actual fetching for all projects that registered their desire for getting the project state (see function: ProjectCache::fetch_states ). TODO: Add pseudo code UpdateLocalStates Updates project states for project states comming from a local file configuration.(TODO check if that is correct RaduW. 10.Oct.2019) This message is emmited periodically by a thread that loops and periodically checks the local file system for configuration changes (see function: poll_local_states ). Store endpoint request processing graph LR Store>/api/#PRJ#/store<br/>store.storeEvent] Upstream(UpstreamRelay) EvMan(EventManager) Proj(Project) EvProc[\"EventProcessor <br/>(sync)\"] Cache(ProjectCache) StoreF(StoreForwarder) Store-->|GetEventAction|Proj Store-->|GetProject|Cache Store-->|QueueEvent|EvMan Proj-->|FetchProjectState|Cache EvMan-->|GetProjectState|Proj EvMan-->|GetEventAction|Proj EvMan-->|RateLimit|Proj EvMan-->|HandleEvent|EvMan EvMan-->|GetProjectId|Proj EvMan-->|ProcessEvent|EvProc EvMan-->|StoreEvent|StoreF EvMan-->|SendRequest|Upstream Cache-->|UpdateLocalStates|Cache Event ingestion Title : Event Ingestion store_event --> ProjectCache : GetProject ProjectCache --> store_event : Project store_event --> Project : GetEventAction Project --> store_event : EventAction store_event --> EventManager : QueueEvent EventManager --> store_event : event_id EventManager --> EventManager : HandleEvent EventManager --> Project : GetProjectId Project --> EventManager : ProjectId EventManager --> Project : GetEventAction Project --> EventManager : EventAction EventManager --> Project : GetProjectState Project --> EventManager : ProjectState EventManager --> EventProcessor : ProcessEvent EventProcessor --> EventManager : ProcessEventResponse Server bootstrap main.main->cli.execute: cli.execute->cli.execute:make_app cli.execute->server.lib.run: server.lib.run->Controller: run Controller->server.actors.Server: start server.actors.Server->server.service:start server.service->ServiceState: start ServiceState start ServiceState->UpstreamRelay:start(config) ServiceState->EventManager:start(config, upstream_realy) ServiceState->KeyCache:start(config,upstream_relay) ServiceState->ProjectCache:start(config, upstream_relay)","title":"Actors"},{"location":"architecture/actors/#actors","text":"This document describes how Relay works through the perspective of the system actors and the messages exchanged by them. TODO Short description about infrastructure (i.e. actix-web, actix, tokio, futures), note that we are using the old style Future trait, and actix 0.7.x .","title":"Actors"},{"location":"architecture/actors/#controllerrs","text":"","title":"controller.rs"},{"location":"architecture/actors/#eventsrs","text":"The events.rs module contains functionality related to the processing of events. Raw events being sent to the system are first processed, and then sent to Sentry for saving. The module contains to actors: EventManager : an actor that receives all events, checks if the event should be processed (i.e. it is not filtered) and orchestrates all data needed for event processing. If the event should be processed it is passed to the EventProcessor . There is one EventManager in the system. EventProcessor : an CPU bound actor that receives all necessary project configuration and does the heavy lifting of processing the message (normalisation, PII stripping ...). There are multiple EventProcessor actors running in a thread pool.","title":"events.rs"},{"location":"architecture/actors/#eventmanager","text":"The EventManager is an actor running in the main system arbiter. The system arbiter is a asynchronous arbiter created when Relay starts. The upshot of this is that all processing done by the event manager should be extremly quick. It is ok to wait on I/O but no significant processing may be done in the EventManager . Once the EventManager had obtained the project state and had decided that the event should be processed the EventManager passes the event to the EventProcessor actors. TODO document all handlers","title":"EventManager"},{"location":"architecture/actors/#eventprocessor","text":"The EventProcessor is an actor running in a SyncArbiter. There are multiple instances of the EventProcessor actor (roughly 1 per thread) ( TODO RaduW check that I'm not talking nonsense here.). The EventProcessor does the heavy lifting of event processing. The event processing does only synchronous work ( all the IO is handleed in the EventManager and all the needed state is passed to the EventProcessor ) Since all the work done by the event processor is the synchronous processing of an event there is only one type of message accepted by the EventProcessor actor:","title":"EventProcessor"},{"location":"architecture/actors/#processevent","text":"The ProcessEvent handler prepares the event for ingestion. It normalizes the event, symbolicates its stack-trace and strips sensitive information (PPI stripping). TODO finish here","title":"ProcessEvent"},{"location":"architecture/actors/#keysrs","text":"","title":"keys.rs"},{"location":"architecture/actors/#outcomers","text":"","title":"outcome.rs"},{"location":"architecture/actors/#serverrs","text":"","title":"server.rs"},{"location":"architecture/actors/#storers","text":"","title":"store.rs"},{"location":"architecture/actors/#upstreamrs","text":"","title":"upstream.rs"},{"location":"architecture/actors/#projectrs","text":"The project.rs module contains functionality related to the project state. Sentry events belong to projects and projects belong to organizations (Relay doesn't care at the moment about organizations). Projects serve to group the events (so that each Sentry customer can only see and deal with his/hers own events) and prescribe how messages are to be processed ( what should be filtered, which data inside the event should be anonymised (i.e PPI stripping), etc). All activities around obtaining, caching and refreshing the project state is handled in this module. The module contains two actors: Project : an actor that holds project data ProjectCache : an actor that holds references to Project actors. From a high level perspective one obtains a Project from the ProjectCache and then uses the Project in order to get 'project specific' information.","title":"project.rs"},{"location":"architecture/actors/#project","text":"The Project actor is responsible with decisions about how an event for a particular project should be handled. The project runs in an async arbiter ( I think it actully runs in the SystemArbiter TODO check ir that is true, or if it runs in another async arbiter). The system constructs an actor for each project used. The Project actor runs in an async context. The Project actor responds to the following message types:","title":"Project"},{"location":"architecture/actors/#getprojectid","text":"The GetProjectId handler returns the project_id (trivial functionality).","title":"GetProjectId"},{"location":"architecture/actors/#getprojectstate","text":"The handler retuns the ProjectState , either directly (if it has a recent cached version) or by asking the ProjectCache to fetch it on its behalf.","title":"GetProjectState"},{"location":"architecture/actors/#pseudo-code","text":"if 'we have an up-to-date project state' return self . project_state if not self . receiver : # we don't have an already active request for the project state channel , receiver = 'create a channel and save its receiver' async : # ops that run at some time in the future project_state = await ProjectCache . send ( FetchProjectState ) channel . sender . push ( project_state ) # put the state on the channel when available channel = None # clenaup after we have pushed the ProjectState return future ( receiver ) # a Future that resolves with the ProjectState when available","title":"Pseudo Code"},{"location":"architecture/actors/#geteventaction","text":"The handler answers the question: How should an event be handled? An event may be handled in one of three ways specified by the EventAction enum. pub enum EventAction { /// The event should be discarded. Discard ( DiscardReason ), /// The event should be discarded and the client should back off for some time. RetryAfter ( RateLimit ), /// The event should be processed and sent to upstream. Accept , }","title":"GetEventAction"},{"location":"architecture/actors/#pseudo-code_1","text":"if 'we have a cached rate limit value for the current event key' : return RetryAfter # the event is discarded without further processing if 'we have a recent project state' # Ask the ProjectState what to do with the msg return projectState . get_event_action ( event ) # No recent ProjectState, fetch it from the ProjectCache actor async : # ops that run at soem time in the future projectState = await ProjectCache . send ( FetchProjectState ) # return a future that will resolve when the project state becomes avaialble return future ( projectState . get_event_action ( event ))","title":"Pseudo Code"},{"location":"architecture/actors/#ratelimit","text":"The handler is used to update chached versions of project RateLimits.","title":"RateLimit"},{"location":"architecture/actors/#pseudo-code_2","text":"if rate_limit . type not in self . rate_limit_cache self . rate_limit_cache . insert ( rate_limit ) # insert a new rate limit else if \"rate_limit expires sooner than the old cached value\" : self . rate_limit_cache . insert ( rate_limit ) # update old rate limit","title":"Pseudo Code"},{"location":"architecture/actors/#projectcache","text":"The ProjectCache actor is responsible for providing Project actors. The ProjectCache runs in an asynchronous context. There is only one instance of the ProjectCache in the system. The project runs in an async arbiter ( I think it actully runs in the SystemArbiter TODO check ir that is true, or if it runs in another async arbiter). The ProjectCache actor responds to the following messages:","title":"ProjectCache"},{"location":"architecture/actors/#getproject","text":"Retuns a Project actor for the required project.","title":"GetProject"},{"location":"architecture/actors/#pseudo-code_3","text":"if project_id not in self . project_cache : project = Project ( project_id ) project . start () self . project_cache [ project_id ] = project return self . project_cache [ porject_id ]","title":"Pseudo Code"},{"location":"architecture/actors/#fetchprojectstate","text":"Registers the intention of a project to retrieve the project state. The FetchProjectState functionality logicaly belongs to the Project actor but it is handled by the ProjectCache in order to batch requests for the project state from multiple Project actors. A Project registers its desire to obtain its project state with the ProjectCache by sending the FetchProjectState and the ProjectCache batches all requests during a batching period and emits one request to the upstream (another Relay or the Sentry server) for all required project states. The handler checks if there is already a scheduled time for fetching project states and, if not, it schedules a delayed function that will do the actual fetching for all projects that registered their desire for getting the project state (see function: ProjectCache::fetch_states ). TODO: Add pseudo code","title":"FetchProjectState"},{"location":"architecture/actors/#updatelocalstates","text":"Updates project states for project states comming from a local file configuration.(TODO check if that is correct RaduW. 10.Oct.2019) This message is emmited periodically by a thread that loops and periodically checks the local file system for configuration changes (see function: poll_local_states ). Store endpoint request processing graph LR Store>/api/#PRJ#/store<br/>store.storeEvent] Upstream(UpstreamRelay) EvMan(EventManager) Proj(Project) EvProc[\"EventProcessor <br/>(sync)\"] Cache(ProjectCache) StoreF(StoreForwarder) Store-->|GetEventAction|Proj Store-->|GetProject|Cache Store-->|QueueEvent|EvMan Proj-->|FetchProjectState|Cache EvMan-->|GetProjectState|Proj EvMan-->|GetEventAction|Proj EvMan-->|RateLimit|Proj EvMan-->|HandleEvent|EvMan EvMan-->|GetProjectId|Proj EvMan-->|ProcessEvent|EvProc EvMan-->|StoreEvent|StoreF EvMan-->|SendRequest|Upstream Cache-->|UpdateLocalStates|Cache Event ingestion Title : Event Ingestion store_event --> ProjectCache : GetProject ProjectCache --> store_event : Project store_event --> Project : GetEventAction Project --> store_event : EventAction store_event --> EventManager : QueueEvent EventManager --> store_event : event_id EventManager --> EventManager : HandleEvent EventManager --> Project : GetProjectId Project --> EventManager : ProjectId EventManager --> Project : GetEventAction Project --> EventManager : EventAction EventManager --> Project : GetProjectState Project --> EventManager : ProjectState EventManager --> EventProcessor : ProcessEvent EventProcessor --> EventManager : ProcessEventResponse Server bootstrap main.main->cli.execute: cli.execute->cli.execute:make_app cli.execute->server.lib.run: server.lib.run->Controller: run Controller->server.actors.Server: start server.actors.Server->server.service:start server.service->ServiceState: start ServiceState start ServiceState->UpstreamRelay:start(config) ServiceState->EventManager:start(config, upstream_realy) ServiceState->KeyCache:start(config,upstream_relay) ServiceState->ProjectCache:start(config, upstream_relay)","title":"UpdateLocalStates"},{"location":"architecture/ingest-event-path/","text":"Path of an Event through Relay Overview Simplified overview of event ingestion (ignores snuba/postprocessing): graph LR loadbalancer(Load Balancer) relay(Relay) projectconfigs(\"Project config endpoint (in Sentry)\") ingestconsumer(Ingest Consumer) outcomesconsumer(Outcomes Consumer) preprocess{\"<code>preprocess_event</code><br>(just a function call now)\"} process(<code>process_event</code>) save(<code>save_event</code>) loadbalancer-->relay relay---projectconfigs relay-->ingestconsumer relay-->outcomesconsumer ingestconsumer-->preprocess preprocess-->process preprocess-->save process-->save Processing enabled vs not? Relay can run as part of a Sentry installation, such as within sentry.io 's infrastructure, or next to the application as a forwarding proxy. A lot of steps described here are skipped or run in a limited form when Relay is not running with processing enabled: Event normalization does different (less) things. In certain modes, project config is not fetched from Sentry at all (but rather from disk or filled out with defaults). Events are forwarded to an HTTP endpoint instead of being written to Kafka. Rate limits are not calculated using Redis, instead Relay just honors 429s from previously mentioned endpoint. Filters are not applied at all. Inside the endpoint When an SDK hits /api/X/store on Relay, the code in server/src/endpoints/store.rs is called before returning a HTTP response. That code looks into an in-memory cache to answer basic information about a project such as: Does it exist? Is it suspended/disabled? Is it rate limited right now? If so, which key is rate limited? Which DSNs are valid for this project? Some of the data for this cache is coming from the projectconfigs endpoint . It is refreshed every couple of minutes, depending on configuration ( project_expiry ). If the cache is fresh, we may return a 429 for rate limits or a 4xx for invalid auth information. That cache might be empty or stale. If that is the case, Relay does not actually attempt to populate it at this stage. It just returns a 200 even though the event might be dropped later. This implies: The first store request that runs into a rate limit doesn't actually result in a 429 , but a subsequent request will (because by that time the project cache will have been updated). A store request for a non-existent project may result in a 200 , but subsequent ones will not. A store request with wrong auth information may result in a 200 , but subsequent ones will not. Filters are also not applied at this stage, so a filtered event will always result in a 200 . This matches the Python behavior since a while now . These examples assume that a project receives one event at a time. In practice one may observe that a highly concurrent burst of store requests for a single project results in 200 OK s only. However, a multi-second flood of incoming events should quickly result in eventually consistent and correct status codes. The response is completed at this point. All expensive work (such as talking to external services) is deferred into a background task. Except for responding to the HTTP request, there's no I/O done in the endpoint in any form. We didn't even hit Redis to calculate rate limits. Summary The HTTP response returned is just a best-effort guess at what the actual outcome of the event is going to be. We only return a 4xx code if we know that the response will fail (based on cached information), if we don't we return a 200 and continue to process the event asynchronously. This asynchronous processing used to happen synchronously in the Python implementation of StoreView . The effect of this is that the server will respond much faster that before but we might return 200 for events that will ultimately not be accepted. Generally Relay will return a 200 in many more situations than the old StoreView . The background task The HTTP response is out by now. The rest of what used to happen synchronously in the Python StoreView is done asynchronously, but still in the same process. So, now to the real work: Project config is fetched. If the project cache is stale or missing, we fetch it. We may wait a couple milliseconds ( batch_interval ) here to be able to batch multiple project config fetches into the same HTTP request to not overload Sentry too much. At this stage Relay may drop the event because it realized that the DSN was invalid or the project didn't even exist. The next incoming event will get a proper 4xx status code. The event is parsed. In the endpoint we only did decompression, a basic JSON syntax check, and extraction of the event ID to be able to return it as part of the response. Now we create an Event struct, which conceptually is the equivalent to parsing it into a Python dictionary: We allocate more memory. The event is normalized. Event normalization is probably the most CPU-intensive task running in Relay. It discards invalid data, moves data from deprecated fields to newer fields and generally just does schema validation. Filters (\"inbound filters\") are applied. Event may be discarded because of IP addresses, patterns on the error message or known web crawlers. Exact rate limits (\"quotas\") are applied. is_rate_limited.lua is executed on Redis. The input parameters for is_rate_limited.lua (\"quota objects\") are part of the project config. See this pull request for an explanation of what quota objects are. The event may be discarded here. If so, we write the rate limit info (reason and expiration timestamp) into the in-memory project cache so that the next store request returns a 429 in the endpoint and doesn't hit Redis at all. This contraption has the advantage that suspended or permanently rate-limited projects are very cheap to handle, and do not involve external services (ignoring the polling of the project config every couple of minutes). The event is datascrubbed. We have a PII config (new format) and a datascrubbing config (old format, converted to new format on the fly) as part of the project config fetched from Sentry. Event is written to Kafka. Note: If we discard an event at any point, an outcome is written to Kafka if Relay is configured to do so. Summary For events that returned a 200 we spawn an in-process background task that does the rest of what the old StoreView did. This task updates in-memory state for rate limits and disabled projects/keys. The outcomes consumer Outcomes are small messages in Kafka that contain an event ID and information about whether that event was rejected, and if so, why. The outcomes consumer is mostly responsible for updating (user-visible) counters in Sentry (buffers/counters and tsdb, which are two separate systems). The ingest consumer The ingest consumer reads accepted events from Kafka, and also updates some stats. Some of those stats are billing-relevant. Its main purpose is to do what insert_data_to_database in Python store did: Call preprocess_event , after which comes sourcemap processing, native symbolication, grouping, snuba and all that other stuff that is of no concern to Relay. Sequence diagram of components inside Relay sequenceDiagram participant sdk as SDK participant endpoint as Endpoint participant projectcache as ProjectCache participant eventmanager as EventManager participant cpupool as CPU Pool sdk->>endpoint:POST /api/42/store activate endpoint endpoint->>projectcache: get project (cached only) activate projectcache projectcache-->>endpoint: return project deactivate projectcache Note over endpoint: Checking rate limits and auth (fast path) endpoint->>eventmanager: queue event activate eventmanager eventmanager-->>endpoint:event ID endpoint-->>sdk:200 OK deactivate endpoint eventmanager->>projectcache:fetch project activate projectcache Note over eventmanager,projectcache: web request (batched with other projects) projectcache-->>eventmanager: return project deactivate projectcache eventmanager->>cpupool: . activate cpupool Note over eventmanager,cpupool: normalization, datascrubbing, redis rate limits, ... cpupool-->>eventmanager: . deactivate cpupool Note over eventmanager: Send event to kafka deactivate eventmanager","title":"Path of an Event through Relay"},{"location":"architecture/ingest-event-path/#path-of-an-event-through-relay","text":"","title":"Path of an Event through Relay"},{"location":"architecture/ingest-event-path/#overview","text":"Simplified overview of event ingestion (ignores snuba/postprocessing): graph LR loadbalancer(Load Balancer) relay(Relay) projectconfigs(\"Project config endpoint (in Sentry)\") ingestconsumer(Ingest Consumer) outcomesconsumer(Outcomes Consumer) preprocess{\"<code>preprocess_event</code><br>(just a function call now)\"} process(<code>process_event</code>) save(<code>save_event</code>) loadbalancer-->relay relay---projectconfigs relay-->ingestconsumer relay-->outcomesconsumer ingestconsumer-->preprocess preprocess-->process preprocess-->save process-->save","title":"Overview"},{"location":"architecture/ingest-event-path/#processing-enabled-vs-not","text":"Relay can run as part of a Sentry installation, such as within sentry.io 's infrastructure, or next to the application as a forwarding proxy. A lot of steps described here are skipped or run in a limited form when Relay is not running with processing enabled: Event normalization does different (less) things. In certain modes, project config is not fetched from Sentry at all (but rather from disk or filled out with defaults). Events are forwarded to an HTTP endpoint instead of being written to Kafka. Rate limits are not calculated using Redis, instead Relay just honors 429s from previously mentioned endpoint. Filters are not applied at all.","title":"Processing enabled vs not?"},{"location":"architecture/ingest-event-path/#inside-the-endpoint","text":"When an SDK hits /api/X/store on Relay, the code in server/src/endpoints/store.rs is called before returning a HTTP response. That code looks into an in-memory cache to answer basic information about a project such as: Does it exist? Is it suspended/disabled? Is it rate limited right now? If so, which key is rate limited? Which DSNs are valid for this project? Some of the data for this cache is coming from the projectconfigs endpoint . It is refreshed every couple of minutes, depending on configuration ( project_expiry ). If the cache is fresh, we may return a 429 for rate limits or a 4xx for invalid auth information. That cache might be empty or stale. If that is the case, Relay does not actually attempt to populate it at this stage. It just returns a 200 even though the event might be dropped later. This implies: The first store request that runs into a rate limit doesn't actually result in a 429 , but a subsequent request will (because by that time the project cache will have been updated). A store request for a non-existent project may result in a 200 , but subsequent ones will not. A store request with wrong auth information may result in a 200 , but subsequent ones will not. Filters are also not applied at this stage, so a filtered event will always result in a 200 . This matches the Python behavior since a while now . These examples assume that a project receives one event at a time. In practice one may observe that a highly concurrent burst of store requests for a single project results in 200 OK s only. However, a multi-second flood of incoming events should quickly result in eventually consistent and correct status codes. The response is completed at this point. All expensive work (such as talking to external services) is deferred into a background task. Except for responding to the HTTP request, there's no I/O done in the endpoint in any form. We didn't even hit Redis to calculate rate limits. Summary The HTTP response returned is just a best-effort guess at what the actual outcome of the event is going to be. We only return a 4xx code if we know that the response will fail (based on cached information), if we don't we return a 200 and continue to process the event asynchronously. This asynchronous processing used to happen synchronously in the Python implementation of StoreView . The effect of this is that the server will respond much faster that before but we might return 200 for events that will ultimately not be accepted. Generally Relay will return a 200 in many more situations than the old StoreView .","title":"Inside the endpoint"},{"location":"architecture/ingest-event-path/#the-background-task","text":"The HTTP response is out by now. The rest of what used to happen synchronously in the Python StoreView is done asynchronously, but still in the same process. So, now to the real work: Project config is fetched. If the project cache is stale or missing, we fetch it. We may wait a couple milliseconds ( batch_interval ) here to be able to batch multiple project config fetches into the same HTTP request to not overload Sentry too much. At this stage Relay may drop the event because it realized that the DSN was invalid or the project didn't even exist. The next incoming event will get a proper 4xx status code. The event is parsed. In the endpoint we only did decompression, a basic JSON syntax check, and extraction of the event ID to be able to return it as part of the response. Now we create an Event struct, which conceptually is the equivalent to parsing it into a Python dictionary: We allocate more memory. The event is normalized. Event normalization is probably the most CPU-intensive task running in Relay. It discards invalid data, moves data from deprecated fields to newer fields and generally just does schema validation. Filters (\"inbound filters\") are applied. Event may be discarded because of IP addresses, patterns on the error message or known web crawlers. Exact rate limits (\"quotas\") are applied. is_rate_limited.lua is executed on Redis. The input parameters for is_rate_limited.lua (\"quota objects\") are part of the project config. See this pull request for an explanation of what quota objects are. The event may be discarded here. If so, we write the rate limit info (reason and expiration timestamp) into the in-memory project cache so that the next store request returns a 429 in the endpoint and doesn't hit Redis at all. This contraption has the advantage that suspended or permanently rate-limited projects are very cheap to handle, and do not involve external services (ignoring the polling of the project config every couple of minutes). The event is datascrubbed. We have a PII config (new format) and a datascrubbing config (old format, converted to new format on the fly) as part of the project config fetched from Sentry. Event is written to Kafka. Note: If we discard an event at any point, an outcome is written to Kafka if Relay is configured to do so. Summary For events that returned a 200 we spawn an in-process background task that does the rest of what the old StoreView did. This task updates in-memory state for rate limits and disabled projects/keys.","title":"The background task"},{"location":"architecture/ingest-event-path/#the-outcomes-consumer","text":"Outcomes are small messages in Kafka that contain an event ID and information about whether that event was rejected, and if so, why. The outcomes consumer is mostly responsible for updating (user-visible) counters in Sentry (buffers/counters and tsdb, which are two separate systems).","title":"The outcomes consumer"},{"location":"architecture/ingest-event-path/#the-ingest-consumer","text":"The ingest consumer reads accepted events from Kafka, and also updates some stats. Some of those stats are billing-relevant. Its main purpose is to do what insert_data_to_database in Python store did: Call preprocess_event , after which comes sourcemap processing, native symbolication, grouping, snuba and all that other stuff that is of no concern to Relay.","title":"The ingest consumer"},{"location":"architecture/ingest-event-path/#sequence-diagram-of-components-inside-relay","text":"sequenceDiagram participant sdk as SDK participant endpoint as Endpoint participant projectcache as ProjectCache participant eventmanager as EventManager participant cpupool as CPU Pool sdk->>endpoint:POST /api/42/store activate endpoint endpoint->>projectcache: get project (cached only) activate projectcache projectcache-->>endpoint: return project deactivate projectcache Note over endpoint: Checking rate limits and auth (fast path) endpoint->>eventmanager: queue event activate eventmanager eventmanager-->>endpoint:event ID endpoint-->>sdk:200 OK deactivate endpoint eventmanager->>projectcache:fetch project activate projectcache Note over eventmanager,projectcache: web request (batched with other projects) projectcache-->>eventmanager: return project deactivate projectcache eventmanager->>cpupool: . activate cpupool Note over eventmanager,cpupool: normalization, datascrubbing, redis rate limits, ... cpupool-->>eventmanager: . deactivate cpupool Note over eventmanager: Send event to kafka deactivate eventmanager","title":"Sequence diagram of components inside Relay"},{"location":"architecture/project-configuration/","text":"Project configuration This document describes how Relay deals with project configurations. Overview Getting a project Here is how we obtain a Project actor ( used to get project configuration). Legend Redis Proj Cache = Redis Project Cache Upstream Source = Upstream Project Source sequenceDiagram participant extern as Some Actor participant projCache as Project Cache participant proj as Project participant redis as Redis Proj Cache participant upstream as Upstream Source Note over extern, upstream : Getting a Project returns a Project actor from the cache or simply creates a new Project actor and returns it extern->>projCache: GetProject(projId) activate projCache alt projId in ProjectCache projCache-->>extern: Project else projeId not found in cache projCache->>projCache: Project::new(projId, now) projCache-->>extern: Project end deactivate projCache Getting a project state Here is how we obtain project configuration. Legend Proj Cache = Project Cache Proj Loc Info = Project Local Info Redis Proj Cache = Redis Project Cache Upstream Source = Upstream Project Source sequenceDiagram participant extern as Some Actor participant projCache as Proj Cache participant local as Proj Loc Info participant proj as Project participant redis as Redis Proj Cache participant upstream as Upstream Source Note over extern, upstream : Fetching a Project state extern->>projCache: FetchProjectState(projId) activate projCache opt proj in cache Note right of projCache: Update last used projCache->>projCache: proj.last_update = now end opt projectLocal != None projCache ->> local: FetchOptionalProjectState(projId) activate local local -->> projCache: Option<ProjectState> deactivate local end alt projState != None projCache -->>extern: ProjectState else projState == None opt has redis cache projCache ->> redis: FetchOptionalProjectState(projId) activate redis redis -->> projCache: Option<ProjectState> deactivate redis end alt projState != None projCache -->> extern: ProjectState else projState == None projCache ->> upstream: FetchProjectState(projId) activate upstream upstream -->> extern: ProjectState deactivate upstream end end deactivate projCache Fetching the project state from Redis Fetching the project state from redis is straight forward. Relay does not do any sort of management of project states in Redis. From Relay's point of view a project state is either in Redis (and then it uses it as a result) or it isn't and then it looks for the project state in other places (upstream). If Relay obtains the project state from Upstream it will NOT insert it in Redis. It is up to other, external systems, to manage project states and add/remove/refresh them in Redis. Fetching the project state from Upstream If everything else fails and the ProjectCache can't obtain a project state from one of the chaches the Upstream will be queried for the ProjectState. Here's what happens in the Upstream actor Legend State Channel - Project State Channel Upstream Source - Upstream Project Source sequenceDiagram participant extern as Some Actor participant upstream as Upstream Source participant timer as Timer participant channel as State Channel participant http as Upstream Source extern->>upstream: FetchProjectState(projId) activate extern activate upstream upstream-->>timer: schedule_fetch() activate timer note right of upstream: Will return the <br> receiver of a <br> Project Channel upstream->>upstream: getOrCreateChannel(projId) note right of timer: at regular intervals timer->>upstream: fetch_states() deactivate timer activate upstream loop batch requests upstream->>http: GetProjectStates() activate http http->>upstream: GetProjectStatesResponse deactivate http end loop project states upstream->>channel: send(ProjectState) activate channel deactivate upstream end deactivate upstream channel->>extern: ProjectState deactivate channel deactivate extern .","title":"Project configuration"},{"location":"architecture/project-configuration/#project-configuration","text":"This document describes how Relay deals with project configurations.","title":"Project configuration"},{"location":"architecture/project-configuration/#overview","text":"","title":"Overview"},{"location":"architecture/project-configuration/#getting-a-project","text":"Here is how we obtain a Project actor ( used to get project configuration). Legend Redis Proj Cache = Redis Project Cache Upstream Source = Upstream Project Source sequenceDiagram participant extern as Some Actor participant projCache as Project Cache participant proj as Project participant redis as Redis Proj Cache participant upstream as Upstream Source Note over extern, upstream : Getting a Project returns a Project actor from the cache or simply creates a new Project actor and returns it extern->>projCache: GetProject(projId) activate projCache alt projId in ProjectCache projCache-->>extern: Project else projeId not found in cache projCache->>projCache: Project::new(projId, now) projCache-->>extern: Project end deactivate projCache","title":"Getting a project"},{"location":"architecture/project-configuration/#getting-a-project-state","text":"Here is how we obtain project configuration. Legend Proj Cache = Project Cache Proj Loc Info = Project Local Info Redis Proj Cache = Redis Project Cache Upstream Source = Upstream Project Source sequenceDiagram participant extern as Some Actor participant projCache as Proj Cache participant local as Proj Loc Info participant proj as Project participant redis as Redis Proj Cache participant upstream as Upstream Source Note over extern, upstream : Fetching a Project state extern->>projCache: FetchProjectState(projId) activate projCache opt proj in cache Note right of projCache: Update last used projCache->>projCache: proj.last_update = now end opt projectLocal != None projCache ->> local: FetchOptionalProjectState(projId) activate local local -->> projCache: Option<ProjectState> deactivate local end alt projState != None projCache -->>extern: ProjectState else projState == None opt has redis cache projCache ->> redis: FetchOptionalProjectState(projId) activate redis redis -->> projCache: Option<ProjectState> deactivate redis end alt projState != None projCache -->> extern: ProjectState else projState == None projCache ->> upstream: FetchProjectState(projId) activate upstream upstream -->> extern: ProjectState deactivate upstream end end deactivate projCache","title":"Getting a project state"},{"location":"architecture/project-configuration/#fetching-the-project-state-from-redis","text":"Fetching the project state from redis is straight forward. Relay does not do any sort of management of project states in Redis. From Relay's point of view a project state is either in Redis (and then it uses it as a result) or it isn't and then it looks for the project state in other places (upstream). If Relay obtains the project state from Upstream it will NOT insert it in Redis. It is up to other, external systems, to manage project states and add/remove/refresh them in Redis.","title":"Fetching the project state from Redis"},{"location":"architecture/project-configuration/#fetching-the-project-state-from-upstream","text":"If everything else fails and the ProjectCache can't obtain a project state from one of the chaches the Upstream will be queried for the ProjectState. Here's what happens in the Upstream actor Legend State Channel - Project State Channel Upstream Source - Upstream Project Source sequenceDiagram participant extern as Some Actor participant upstream as Upstream Source participant timer as Timer participant channel as State Channel participant http as Upstream Source extern->>upstream: FetchProjectState(projId) activate extern activate upstream upstream-->>timer: schedule_fetch() activate timer note right of upstream: Will return the <br> receiver of a <br> Project Channel upstream->>upstream: getOrCreateChannel(projId) note right of timer: at regular intervals timer->>upstream: fetch_states() deactivate timer activate upstream loop batch requests upstream->>http: GetProjectStates() activate http http->>upstream: GetProjectStatesResponse deactivate http end loop project states upstream->>channel: send(ProjectState) activate channel deactivate upstream end deactivate upstream channel->>extern: ProjectState deactivate channel deactivate extern .","title":"Fetching the project state from Upstream"},{"location":"configuration/metrics/","text":"Errors and Metrics Error Reporting By default, Relay logs errors to the configured logger. You can enable error reporting to your own project in Sentry in the configuration file: sentry : enabled : true dsn : <your_dsn> Configuration Stats can be submitted to a statsd server by configuring metrics key. It can be put to a ip:port tuple: metrics : statsd : 127.0.0.1:8126 prefix : mycompany.relay statsd Configures the host and port of the statsd client. We recommend to run a statsd client on the same host as Relay for performance reasons. prefix Configures a prefix that is prepended to all reported metrics. By default, all metrics are reported with a \"sentry.relay\" prefix. hostname_tag Adds a tag of the given name and sets it to the hostname of the machine that is running Relay. This is useful to separate multiple Relays. For example, setting this to: metrics : hostname_tag : pod_name The above example adds a \"pod_name\" tag that is set to the host name to every metric. Metrics Relay emits the following metrics: event.queue_size.pct Histogram. The number of envelopes in the queue as a percentage of the maximum number of envelopes that can be stored in the queue. The value ranges from 0 (the queue is empty) to 1 (the queue is full and no additional events can be added). event.queue_size Histogram. The number of envelopes in the queue. The event queue represents the envelopes that are being processed at a particular time in Relay. Once a request is received, the envelope receives some preliminary (quick) processing to determine if it can be processed or it is rejected. Once this determination has been done, the http request that created the envelope terminates and, if the request is to be further processed, the envelope enters a queue. Once the envelope finishes processing and is sent downstream, the envelope is considered handled and it leaves the queue. event.size_bytes.raw Histogram. The size of the request body as seen by Relay after it is extracted from a request. For envelope requests, this is the full size of the envelope. For JSON store requests, this is the size of the JSON body. If this request contains a base64 zlib compressed payload without a proper content-encoding header, then this is the size before decompression. event.size_bytes.uncompressed Histogram. The size of the request body as seen by Relay after it has been decompressed and decoded in case this request contains a base64 zlib compressed payload without a proper content-encoding header. Otherwise, this metric is always equal to event.size_bytes.raw . project_state.pending Histogram. Number of projects in the in-memory project cache that are waiting for their state to be updated. project_state.request.batch_size Histogram. Number of project states requested from the Upstream for the current batch request. project_state.received Histogram. Number of project states received from the Upstream for the current batch request. project_cache.size Histogram. Number of project states currently held in the in-memory project cache. connector.wait_queue Histogram. The number of upstream requests queued up for a connection in the connection pool. event_processing.deserialize Timer. The time spent deserializing an event from a JSON byte array into the native data structure on which Relay operates. event_processing.process Note : This metric is emitted only when Relay is built with the processing feature. Timer. Time spent running event processors on an event. Event processing happens before filtering. event_processing.filtering Note : This metric is emitted only when Relay is built with the processing feature. Timer. Time spent running filtering on an event. event_processing.rate_limiting Note : This metric is emitted only when Relay is built with the processing feature. Timer. Time spent checking for rate limits in Redis. Note that not all events are checked against Redis. After an event is rate limited for the first time, the rate limit is cached. Events coming in during this period will be discarded earlier in the request queue and do not reach the processing queue. event_processing.pii Timer. Time spent in data scrubbing for the current event. Data scrubbing happens last before serializing the event back to JSON. event_processing.serialization Timer. Time spent converting the event from its in-memory reprsentation into a JSON string. event.wait_time Timer. Time spent between receiving a request in Relay (that is, beginning of request handling) and the start of synchronous processing in the EventProcessor. This metric primarily indicates backlog in event processing. event.processing_time Timer. The time spent in synchronous processing of envelopes. This timing covers the end-to-end processing in the CPU pool and comprises: event_processing.deserialize event_processing.pii event_processing.serialization With Relay in processing mode, this includes the following additional timings: event_processing.process event_processing.filtering event_processing.rate_limiting event.total_time Timer. The total time an envelope spends in Relay from the time it is received until it finishes processing and has been submitted. project_state.eviction.duration Timer. The total time spent during ProjectCache.fetch_states in which eviction of outdated projects happens. project_state.request.duration Timer. The total time spent during ProjectCache.fetch_states spent waiting for all ProjectState requests to resolve. During a fetch_states request, we pick up to max_num_requests * max_num_project_states_per_request projects that need their state updated and batch them into max_num_requests requests. This metric represents the time spent from issuing the first request until all requests are finished. project_id.request.duration Timer. The total time spent getting the project id from upstream. Note that ProjectIdRequests happen only for the legacy endpoint that does not specify the project id in the url, for the new endpoints the project id is extracted from the url path. Only projects with the id not already fetched are counted. The project id is only fetched once and it is not refreshed. requests.duration Timer. The total duration of a request as seen from Relay from the moment the request is received until a http result is returned. Note that this does not represent the total duration for processing an event. Requests for events that are not immediately rejected ( because the project has hit a rate limit) are scheduled for processing at a latter time and an HTTP OK (200) is returned. unique_projects Set. Represents the number of active projects in the current slice of time event.accepted Counter. Number of envelopes accepted in the current time slot. This represents requests that have successfully passed rate limits, filters and have been successfully handled. event.rejected Counter. Number of envelopes rejected in the current time slot. This includes envelopes being rejected because they are malformed or any other errors during processing (including filtered events, invalid payloads and rate limits). events.outcomes Note : This metric is emitted only when Relay is built with the processing feature. Counter. Represents a group of counters incremented for every outcome emitted by Relay, implemented with tags. The following tags are present for each event outcome: outcome which is an Outcome enumeration reason which is the reason string for all outcomes that are not Accepted . project_state.get Counter. Counts the number of times a project state lookup is done. This includes requests for projects that are cached and requests for projects that are not yet cached. All requests that return a EventAction::Accept i.e. are not rate limited (on the fast path) or are discarded because we know the project is disabled or invalid will be counted. project_state.request Counter. Counts the number of project state http requests. Note that a project state HTTP request typically contains a number of projects (the project state requests are batched). project_cache.hit Counter. Counts the number of times a request for a project is already present, this effectively represents the fraction of project_state.get that will not result in a ProjectState request. project_cache.miss Counter. Counts the number of times a request for a project is not already present. project_state.get = project_cache.miss + project_cache.hit . Requests that are generating a cache hit will be queued and batched and eventually will generate a project_state.request . project_id.request Counter. Counts the number of requests for the ProjectId (the timing is tracked by project_id.request.duration ). Note that ProjectIdRequests happen only for the legacy endpoint that does not specify the project id in the url, for the new endpoints the project id is extracted from the url path. Only projects with the id not already fetched are counted. Once the ProjectId is successfully cached it will be retained indefinitely. server.starting Counter. Counts the number of times Relay started. This can be used to track unwanted restarts due to crashes or termination. processing.event.produced Note : This metric is emitted only when Relay is built with the processing feature. Counter. Counts the number of messages placed on the Kafka queue. When Relay operates with processing enabled and an item is successfully processed, each item will generate a message on the Kafka. The counter has an event_type tag which is set to either event or attachment representing the type of message produced on the Kafka queue. processing.produce.error Note : This metric is emitted only when Relay is built with the processing feature. Counter. Counts the number of producer errors occurred after an event was already enqueued for sending to Kafka. These errors might include e.g. MessageTooLarge errors when the broker does not accept the requests over a certain size, which is usually due to invalic or inconsistent broker/producer configurations. event.protocol Counter. Counts the number of events that hit any of the Store like endpoints (Store, Security, MiniDump, Unreal). The events are counted before they are rate limited , filtered or processed in any way. The counter has a version tag that tracks the message event protocol version. requests Counter. Counts the number of requests reaching Relay. responses.status_codes Counter. Counts the number of requests that have finished during the current interval. The counter has the following tags: status_code The HTTP status code number. method The HTTP method used in the request in uppercase. route Unique dashed identifier of the endpoint. project_cache.eviction Counter. We are scanning our in-memory project cache for stale entries. This counter is incremented before doing the expensive operation. connector.reused Counter. The number of requests that reused an already open upstream connection. Relay employs connection keep-alive whenever possible. Connections are kept open for 15 seconds of inactivity, or 75 seconds of activity. connector.opened Counter. The number of upstream connections opened. connector.closed Counter. The number of upstream connections closed due to connection timeouts. Relay employs connection keep-alive whenever possible. Connections are kept open for 15 seconds of inactivity, or 75 seconds of activity. connector.errors Counter. The number of upstream connections that experienced errors. connector.timeouts Counter. The number of upstream connections that experienced a timeout.","title":"Errors and Metrics"},{"location":"configuration/metrics/#errors-and-metrics","text":"","title":"Errors and Metrics"},{"location":"configuration/metrics/#error-reporting","text":"By default, Relay logs errors to the configured logger. You can enable error reporting to your own project in Sentry in the configuration file: sentry : enabled : true dsn : <your_dsn>","title":"Error Reporting"},{"location":"configuration/metrics/#configuration","text":"Stats can be submitted to a statsd server by configuring metrics key. It can be put to a ip:port tuple: metrics : statsd : 127.0.0.1:8126 prefix : mycompany.relay","title":"Configuration"},{"location":"configuration/metrics/#statsd","text":"Configures the host and port of the statsd client. We recommend to run a statsd client on the same host as Relay for performance reasons.","title":"statsd"},{"location":"configuration/metrics/#prefix","text":"Configures a prefix that is prepended to all reported metrics. By default, all metrics are reported with a \"sentry.relay\" prefix.","title":"prefix"},{"location":"configuration/metrics/#hostname_tag","text":"Adds a tag of the given name and sets it to the hostname of the machine that is running Relay. This is useful to separate multiple Relays. For example, setting this to: metrics : hostname_tag : pod_name The above example adds a \"pod_name\" tag that is set to the host name to every metric.","title":"hostname_tag"},{"location":"configuration/metrics/#metrics","text":"Relay emits the following metrics:","title":"Metrics"},{"location":"configuration/metrics/#eventqueue_sizepct","text":"Histogram. The number of envelopes in the queue as a percentage of the maximum number of envelopes that can be stored in the queue. The value ranges from 0 (the queue is empty) to 1 (the queue is full and no additional events can be added).","title":"event.queue_size.pct"},{"location":"configuration/metrics/#eventqueue_size","text":"Histogram. The number of envelopes in the queue. The event queue represents the envelopes that are being processed at a particular time in Relay. Once a request is received, the envelope receives some preliminary (quick) processing to determine if it can be processed or it is rejected. Once this determination has been done, the http request that created the envelope terminates and, if the request is to be further processed, the envelope enters a queue. Once the envelope finishes processing and is sent downstream, the envelope is considered handled and it leaves the queue.","title":"event.queue_size"},{"location":"configuration/metrics/#eventsize_bytesraw","text":"Histogram. The size of the request body as seen by Relay after it is extracted from a request. For envelope requests, this is the full size of the envelope. For JSON store requests, this is the size of the JSON body. If this request contains a base64 zlib compressed payload without a proper content-encoding header, then this is the size before decompression.","title":"event.size_bytes.raw"},{"location":"configuration/metrics/#eventsize_bytesuncompressed","text":"Histogram. The size of the request body as seen by Relay after it has been decompressed and decoded in case this request contains a base64 zlib compressed payload without a proper content-encoding header. Otherwise, this metric is always equal to event.size_bytes.raw .","title":"event.size_bytes.uncompressed"},{"location":"configuration/metrics/#project_statepending","text":"Histogram. Number of projects in the in-memory project cache that are waiting for their state to be updated.","title":"project_state.pending"},{"location":"configuration/metrics/#project_staterequestbatch_size","text":"Histogram. Number of project states requested from the Upstream for the current batch request.","title":"project_state.request.batch_size"},{"location":"configuration/metrics/#project_statereceived","text":"Histogram. Number of project states received from the Upstream for the current batch request.","title":"project_state.received"},{"location":"configuration/metrics/#project_cachesize","text":"Histogram. Number of project states currently held in the in-memory project cache.","title":"project_cache.size"},{"location":"configuration/metrics/#connectorwait_queue","text":"Histogram. The number of upstream requests queued up for a connection in the connection pool.","title":"connector.wait_queue"},{"location":"configuration/metrics/#event_processingdeserialize","text":"Timer. The time spent deserializing an event from a JSON byte array into the native data structure on which Relay operates.","title":"event_processing.deserialize"},{"location":"configuration/metrics/#event_processingprocess","text":"Note : This metric is emitted only when Relay is built with the processing feature. Timer. Time spent running event processors on an event. Event processing happens before filtering.","title":"event_processing.process"},{"location":"configuration/metrics/#event_processingfiltering","text":"Note : This metric is emitted only when Relay is built with the processing feature. Timer. Time spent running filtering on an event.","title":"event_processing.filtering"},{"location":"configuration/metrics/#event_processingrate_limiting","text":"Note : This metric is emitted only when Relay is built with the processing feature. Timer. Time spent checking for rate limits in Redis. Note that not all events are checked against Redis. After an event is rate limited for the first time, the rate limit is cached. Events coming in during this period will be discarded earlier in the request queue and do not reach the processing queue.","title":"event_processing.rate_limiting"},{"location":"configuration/metrics/#event_processingpii","text":"Timer. Time spent in data scrubbing for the current event. Data scrubbing happens last before serializing the event back to JSON.","title":"event_processing.pii"},{"location":"configuration/metrics/#event_processingserialization","text":"Timer. Time spent converting the event from its in-memory reprsentation into a JSON string.","title":"event_processing.serialization"},{"location":"configuration/metrics/#eventwait_time","text":"Timer. Time spent between receiving a request in Relay (that is, beginning of request handling) and the start of synchronous processing in the EventProcessor. This metric primarily indicates backlog in event processing.","title":"event.wait_time"},{"location":"configuration/metrics/#eventprocessing_time","text":"Timer. The time spent in synchronous processing of envelopes. This timing covers the end-to-end processing in the CPU pool and comprises: event_processing.deserialize event_processing.pii event_processing.serialization With Relay in processing mode, this includes the following additional timings: event_processing.process event_processing.filtering event_processing.rate_limiting","title":"event.processing_time"},{"location":"configuration/metrics/#eventtotal_time","text":"Timer. The total time an envelope spends in Relay from the time it is received until it finishes processing and has been submitted.","title":"event.total_time"},{"location":"configuration/metrics/#project_stateevictionduration","text":"Timer. The total time spent during ProjectCache.fetch_states in which eviction of outdated projects happens.","title":"project_state.eviction.duration"},{"location":"configuration/metrics/#project_staterequestduration","text":"Timer. The total time spent during ProjectCache.fetch_states spent waiting for all ProjectState requests to resolve. During a fetch_states request, we pick up to max_num_requests * max_num_project_states_per_request projects that need their state updated and batch them into max_num_requests requests. This metric represents the time spent from issuing the first request until all requests are finished.","title":"project_state.request.duration"},{"location":"configuration/metrics/#project_idrequestduration","text":"Timer. The total time spent getting the project id from upstream. Note that ProjectIdRequests happen only for the legacy endpoint that does not specify the project id in the url, for the new endpoints the project id is extracted from the url path. Only projects with the id not already fetched are counted. The project id is only fetched once and it is not refreshed.","title":"project_id.request.duration"},{"location":"configuration/metrics/#requestsduration","text":"Timer. The total duration of a request as seen from Relay from the moment the request is received until a http result is returned. Note that this does not represent the total duration for processing an event. Requests for events that are not immediately rejected ( because the project has hit a rate limit) are scheduled for processing at a latter time and an HTTP OK (200) is returned.","title":"requests.duration"},{"location":"configuration/metrics/#unique_projects","text":"Set. Represents the number of active projects in the current slice of time","title":"unique_projects"},{"location":"configuration/metrics/#eventaccepted","text":"Counter. Number of envelopes accepted in the current time slot. This represents requests that have successfully passed rate limits, filters and have been successfully handled.","title":"event.accepted"},{"location":"configuration/metrics/#eventrejected","text":"Counter. Number of envelopes rejected in the current time slot. This includes envelopes being rejected because they are malformed or any other errors during processing (including filtered events, invalid payloads and rate limits).","title":"event.rejected"},{"location":"configuration/metrics/#eventsoutcomes","text":"Note : This metric is emitted only when Relay is built with the processing feature. Counter. Represents a group of counters incremented for every outcome emitted by Relay, implemented with tags. The following tags are present for each event outcome: outcome which is an Outcome enumeration reason which is the reason string for all outcomes that are not Accepted .","title":"events.outcomes"},{"location":"configuration/metrics/#project_stateget","text":"Counter. Counts the number of times a project state lookup is done. This includes requests for projects that are cached and requests for projects that are not yet cached. All requests that return a EventAction::Accept i.e. are not rate limited (on the fast path) or are discarded because we know the project is disabled or invalid will be counted.","title":"project_state.get"},{"location":"configuration/metrics/#project_staterequest","text":"Counter. Counts the number of project state http requests. Note that a project state HTTP request typically contains a number of projects (the project state requests are batched).","title":"project_state.request"},{"location":"configuration/metrics/#project_cachehit","text":"Counter. Counts the number of times a request for a project is already present, this effectively represents the fraction of project_state.get that will not result in a ProjectState request.","title":"project_cache.hit"},{"location":"configuration/metrics/#project_cachemiss","text":"Counter. Counts the number of times a request for a project is not already present. project_state.get = project_cache.miss + project_cache.hit . Requests that are generating a cache hit will be queued and batched and eventually will generate a project_state.request .","title":"project_cache.miss"},{"location":"configuration/metrics/#project_idrequest","text":"Counter. Counts the number of requests for the ProjectId (the timing is tracked by project_id.request.duration ). Note that ProjectIdRequests happen only for the legacy endpoint that does not specify the project id in the url, for the new endpoints the project id is extracted from the url path. Only projects with the id not already fetched are counted. Once the ProjectId is successfully cached it will be retained indefinitely.","title":"project_id.request"},{"location":"configuration/metrics/#serverstarting","text":"Counter. Counts the number of times Relay started. This can be used to track unwanted restarts due to crashes or termination.","title":"server.starting"},{"location":"configuration/metrics/#processingeventproduced","text":"Note : This metric is emitted only when Relay is built with the processing feature. Counter. Counts the number of messages placed on the Kafka queue. When Relay operates with processing enabled and an item is successfully processed, each item will generate a message on the Kafka. The counter has an event_type tag which is set to either event or attachment representing the type of message produced on the Kafka queue.","title":"processing.event.produced"},{"location":"configuration/metrics/#processingproduceerror","text":"Note : This metric is emitted only when Relay is built with the processing feature. Counter. Counts the number of producer errors occurred after an event was already enqueued for sending to Kafka. These errors might include e.g. MessageTooLarge errors when the broker does not accept the requests over a certain size, which is usually due to invalic or inconsistent broker/producer configurations.","title":"processing.produce.error"},{"location":"configuration/metrics/#eventprotocol","text":"Counter. Counts the number of events that hit any of the Store like endpoints (Store, Security, MiniDump, Unreal). The events are counted before they are rate limited , filtered or processed in any way. The counter has a version tag that tracks the message event protocol version.","title":"event.protocol"},{"location":"configuration/metrics/#requests","text":"Counter. Counts the number of requests reaching Relay.","title":"requests"},{"location":"configuration/metrics/#responsesstatus_codes","text":"Counter. Counts the number of requests that have finished during the current interval. The counter has the following tags: status_code The HTTP status code number. method The HTTP method used in the request in uppercase. route Unique dashed identifier of the endpoint.","title":"responses.status_codes"},{"location":"configuration/metrics/#project_cacheeviction","text":"Counter. We are scanning our in-memory project cache for stale entries. This counter is incremented before doing the expensive operation.","title":"project_cache.eviction"},{"location":"configuration/metrics/#connectorreused","text":"Counter. The number of requests that reused an already open upstream connection. Relay employs connection keep-alive whenever possible. Connections are kept open for 15 seconds of inactivity, or 75 seconds of activity.","title":"connector.reused"},{"location":"configuration/metrics/#connectoropened","text":"Counter. The number of upstream connections opened.","title":"connector.opened"},{"location":"configuration/metrics/#connectorclosed","text":"Counter. The number of upstream connections closed due to connection timeouts. Relay employs connection keep-alive whenever possible. Connections are kept open for 15 seconds of inactivity, or 75 seconds of activity.","title":"connector.closed"},{"location":"configuration/metrics/#connectorerrors","text":"Counter. The number of upstream connections that experienced errors.","title":"connector.errors"},{"location":"configuration/metrics/#connectortimeouts","text":"Counter. The number of upstream connections that experienced a timeout.","title":"connector.timeouts"},{"location":"configuration/modes/","text":"Relay Modes When configuring a Relay server, the most important thing it is to understand the major modes in which it can operate. As seen in the introduction, the configuration file contains a relay.mode field. Currently, there are three modes that can be specified: managed , static , proxy . Event processing in Sentry can be configured using a two level hierachical configuration. At the top level, there are organization wide settings. An organization contains projects and event processing can be controlled with settings at project level. From Relay's point of view, events are processed according to the settings of the project it belongs to. Sentry includes all organization settings, such as organization-wide privacy controls, into settings of all projects belonging to your organization. The mode controls the way Relay obtains these project settings. managed Mode This is the default mode in which Relay operates. To activate managed mode, set this configuration: relay : mode : managed Since configuration is obtained from Sentry, authentication is required in this mode. If authentication fails, no events will be accepted by Relay. As Relay receives events from applications, it will request project configurations from Sentry in order to process the events. If Sentry is unable to provide the configuration for a particular project, all messages for that project will be discared. Configuration is refreshed in regular intervals. See Configuration Options for ways to configure intervals, timeouts and retries. static Mode In this mode, projects must be configured manually. To activate static mode, set this configuration: relay : mode : static In static configuration, Relay will process events only for statically configured projects and rejects events for all other projects. This is useful when you know the projects sending events upfront, and you wish to explicitly control the projects that are allowed to send events through this Relay. To configure projects, add files of format projects/<PROJECT_ID>.json to your Relay configuration folder. For a description of the contents of this file, refer to Project Configuration . Note: In static mode, Relay does not register with upstream since it does not query information from it. After processing events for the configured projects, it forwards them to the upstream with the authentication information (DSN) set by the client that sent the original request. proxy Mode This mode is similar to static mode but it forwards events from unknown projects. To activate proxy mode, set this configuration: relay : mode : proxy In proxy mode, events for statically configured projects are handled identically to static mode. Events for unknown projects -- projects for which there are no statically configured settings -- are forwarded (proxied) with minimal processing. Note: Rate limiting is still being applied in proxy mode for all projects regardless of whether they are statically configured or proxied.","title":"Relay Modes"},{"location":"configuration/modes/#relay-modes","text":"When configuring a Relay server, the most important thing it is to understand the major modes in which it can operate. As seen in the introduction, the configuration file contains a relay.mode field. Currently, there are three modes that can be specified: managed , static , proxy . Event processing in Sentry can be configured using a two level hierachical configuration. At the top level, there are organization wide settings. An organization contains projects and event processing can be controlled with settings at project level. From Relay's point of view, events are processed according to the settings of the project it belongs to. Sentry includes all organization settings, such as organization-wide privacy controls, into settings of all projects belonging to your organization. The mode controls the way Relay obtains these project settings.","title":"Relay Modes"},{"location":"configuration/modes/#managed-mode","text":"This is the default mode in which Relay operates. To activate managed mode, set this configuration: relay : mode : managed Since configuration is obtained from Sentry, authentication is required in this mode. If authentication fails, no events will be accepted by Relay. As Relay receives events from applications, it will request project configurations from Sentry in order to process the events. If Sentry is unable to provide the configuration for a particular project, all messages for that project will be discared. Configuration is refreshed in regular intervals. See Configuration Options for ways to configure intervals, timeouts and retries.","title":"managed Mode"},{"location":"configuration/modes/#static-mode","text":"In this mode, projects must be configured manually. To activate static mode, set this configuration: relay : mode : static In static configuration, Relay will process events only for statically configured projects and rejects events for all other projects. This is useful when you know the projects sending events upfront, and you wish to explicitly control the projects that are allowed to send events through this Relay. To configure projects, add files of format projects/<PROJECT_ID>.json to your Relay configuration folder. For a description of the contents of this file, refer to Project Configuration . Note: In static mode, Relay does not register with upstream since it does not query information from it. After processing events for the configured projects, it forwards them to the upstream with the authentication information (DSN) set by the client that sent the original request.","title":"static Mode"},{"location":"configuration/modes/#proxy-mode","text":"This mode is similar to static mode but it forwards events from unknown projects. To activate proxy mode, set this configuration: relay : mode : proxy In proxy mode, events for statically configured projects are handled identically to static mode. Events for unknown projects -- projects for which there are no statically configured settings -- are forwarded (proxied) with minimal processing. Note: Rate limiting is still being applied in proxy mode for all projects regardless of whether they are statically configured or proxied.","title":"proxy Mode"},{"location":"configuration/options/","text":"Configuration Options The base configuration for Relay lives in the file .relay/config.yml . To change this location, pass the --config option to any Relay command: \u276f ./relay run --config /path/to/folder All configuration keys are snake_case . Relay General relay settings for Relay's operation. relay.mode String, default: managed , possible values: managed , static , proxy and capture Controls how Relay obtains the project configuration for events. For detailed explanation of the modes, see Relay Modes . relay.upstream String, default: https://sentry.io Fully qualified URL of the upstream Relay or Sentry instance. Important : Relay does not check for cycles. Ensure this option is not set to an endpoint that will cause events to be cycled back here. relay.host String, default: 0.0.0.0 in Docker, otherwise 127.0.0.1 The host, the Relay should bind to (network interface). Example: 0.0.0.0 relay.port Integer, default: 3000 The port to bind for the unencrypted Relay HTTP server. Example: 3000 relay.tls_port Integer, optional Optional port to bind for the encrypted Relay HTTPS server. Example: 3001 This is in addition to the port option: If you set up a HTTPS server at tls_port , the HTTP server at port still exists. relay.tls_identity_path String, optional The filesystem path to the identity (DER-encoded PKCS12) to use for the HTTPS server. Relative paths are evaluated in the current working directory. Example: relay_dev.pfx relay.tls_identity_password String, optional Password for the PKCS12 archive in relay.tls_identity_path . HTTP Set various network-related settings. http.timeout Integer, default: 5 Timeout for upstream requests in seconds. This timeout covers the time from sending the request until receiving response headers. Neither the connection process and handshakes, nor reading the response body is covered in this timeout. http.connection_timeout Integer, default: 3 Timeout for establishing connections with the upstream in seconds. This includes SSL handshakes. Relay reuses connections when the upstream supports connection keep-alive. Connections are retained for a maximum 75 seconds, or 15 seconds of inactivity. http.max_retry_interval Integer, default: 60 Maximum interval between failed request retries in seconds. host.header string, default: null The custom HTTP Host header to be sent to the upstream. Caching Fine-tune caching of project state. cache.project_expiry Integer, default: 300 (5 minutes) The cache timeout for project configurations in seconds. Irrelevant if you use the \"simple proxy mode\", where your project config is stored in local files. cache.project_grace_period Integer, default: 0 (seconds) Number of seconds to continue using this project configuration after cache expiry while a new state is being fetched. This is added on top of cache.project_expiry and cache.miss_expiry . cache.relay_expiry Integer, default: 3600 (1 hour) The cache timeout for downstream Relay info (public keys) in seconds. This is only relevant, if you plan to connect further Relays to this one. cache.event_expiry Integer, default: 600 (10 minutes) The cache timeout for events (store) before dropping them. cache.miss_expiry Integer, default: 60 (1 minute) The cache timeout for non-existing entries. cache.batch_interval Integer, default: 100 (100 milliseconds) The buffer timeout for batched queries before sending them upstream in milliseconds . cache.batch_size Integer, default: 500 The maximum number of project configs to fetch from Sentry at once. cache.file_interval Integer, default: 10 (10 seconds) Interval for watching local cache override files in seconds. cache.event_buffer_size Integer, default: 1000 The maximum number of events that are buffered in case of network issues or high rates of incoming events. cache.eviction_interval Integer, default: 60 (seconds) Interval for evicting outdated project configs from memory. Size Limits Controls various HTTP-related limits. All values are either integers or are human-readable strings of a number and a human-readable unit, such as: 500B 1kB ( 1,000 bytes) 1KB or 1KiB ( 1,024 bytes) 1MB ( 1,000,000 bytes) 1MiB ( 1,048,576 bytes) limits.max_concurrent_requests Integer, default: 100 The maximum number of concurrent connections to the upstream. If supported by the upstream, Relay supports connection keepalive. limits.max_concurrent_queries Integer, default: 5 The maximum number of queries that can be sent concurrently from Relay to the upstream before Relay starts buffering requests. Queries are all requests made to the upstream for obtaining information and explicitly exclude event submission. The concurrency of queries is additionally constrained by max_concurrent_requests . limits.max_event_size String, default: 1MiB The maximum payload size for events. limits.max_attachment_size String, default: 50MiB The maximum size for each attachment. limits.max_attachments_size String, default: 50MiB The maximum combined size for all attachments in an envelope or request. limits.max_envelope_size String, default: 50MiB The maximum payload size for an entire envelopes. Individual limits still apply. limits.max_session_count Integer, default: 100 The maximum number of session items per envelope. limits.max_api_payload_size String, default: 20MiB The maximum payload size for general API requests. limits.max_api_file_upload_size String, default: 40MiB The maximum payload size for file uploads and chunks. limits.max_api_chunk_upload_size String, default: 100MiB The maximum payload size for chunks limits.max_thread_count Integer, default: number of cpus The maximum number of threads to spawn for CPU and web worker, each. The total number of threads spawned will roughly be 2 * limits.max_thread_count + N , where N is a fixed set of management threads. limits.query_timeout Integer, default: 30 (seconds) The maximum number of seconds a query is allowed to take across retries. Individual requests have lower timeouts. limits.max_connection_rate Integer, default: 256 The maximum number of connections to Relay that can be created at once. limits.max_pending_connections Integer, default: 2048 The maximum number of pending connects to Relay. This corresponds to the backlog param of listen(2) in POSIX. limits.max_connections Integer: default: 25_000 The maximum number of open incoming connections to Relay. limits.shutdown_timeout Integer, default:L 10 (seconds) The maximum number of seconds to wait for pending events after receiving a shutdown signal. Logging logging.level String, default: info The log level for the relay. One of: off error warn info debug trace Warning : On debug and trace levels, Relay emits extremely verbose messages which can have severe impact on application performance. logging.log_failed_payloads boolean, default: false Logs full event payloads of failed events to the log stream. logging.format String, default: auto Controls the log format. One of: auto : Auto detect (pretty for TTY, simplified for other) pretty : Human readable format with colors simplified : Simplified human readable log output json : JSON records, suitable for logging software logging.enable_backtraces boolean, default: true Writes back traces for all internal errors to the log stream and includes them in Sentry errors, if enabled. Statsd Metrics metrics.statsd String, optional If set to a host/port string then metrics will be reported to this statsd instance. metrics.prefix String, default: sentry.relay The prefix that should be added to all metrics. metrics.default_tags Map of strings to strings, default empty A set of default tags that should be attached to all outgoing statsd metrics. metrics.hostname_tag String, optional If set, reports the current hostname under the given tag name for all metrics. Internal Error Reporting Configures error reporting for errors happening within Relay. Disabled by default. sentry.enabled boolean, default: false Whether to report internal errors to a separate DSN. false means no internal errors are sent, but still logged. sentry.dsn String, optional DSN to report internal Relay failures to. It is not a good idea to set this to a value that will make the Relay send errors to itself. Ideally this should just send errors to Sentry directly, not another Relay.","title":"Configuration Options"},{"location":"configuration/options/#configuration-options","text":"The base configuration for Relay lives in the file .relay/config.yml . To change this location, pass the --config option to any Relay command: \u276f ./relay run --config /path/to/folder All configuration keys are snake_case .","title":"Configuration Options"},{"location":"configuration/options/#relay","text":"General relay settings for Relay's operation.","title":"Relay"},{"location":"configuration/options/#relaymode","text":"String, default: managed , possible values: managed , static , proxy and capture Controls how Relay obtains the project configuration for events. For detailed explanation of the modes, see Relay Modes .","title":"relay.mode"},{"location":"configuration/options/#relayupstream","text":"String, default: https://sentry.io Fully qualified URL of the upstream Relay or Sentry instance. Important : Relay does not check for cycles. Ensure this option is not set to an endpoint that will cause events to be cycled back here.","title":"relay.upstream"},{"location":"configuration/options/#relayhost","text":"String, default: 0.0.0.0 in Docker, otherwise 127.0.0.1 The host, the Relay should bind to (network interface). Example: 0.0.0.0","title":"relay.host"},{"location":"configuration/options/#relayport","text":"Integer, default: 3000 The port to bind for the unencrypted Relay HTTP server. Example: 3000","title":"relay.port"},{"location":"configuration/options/#relaytls_port","text":"Integer, optional Optional port to bind for the encrypted Relay HTTPS server. Example: 3001 This is in addition to the port option: If you set up a HTTPS server at tls_port , the HTTP server at port still exists.","title":"relay.tls_port"},{"location":"configuration/options/#relaytls_identity_path","text":"String, optional The filesystem path to the identity (DER-encoded PKCS12) to use for the HTTPS server. Relative paths are evaluated in the current working directory. Example: relay_dev.pfx","title":"relay.tls_identity_path"},{"location":"configuration/options/#relaytls_identity_password","text":"String, optional Password for the PKCS12 archive in relay.tls_identity_path .","title":"relay.tls_identity_password"},{"location":"configuration/options/#http","text":"Set various network-related settings.","title":"HTTP"},{"location":"configuration/options/#httptimeout","text":"Integer, default: 5 Timeout for upstream requests in seconds. This timeout covers the time from sending the request until receiving response headers. Neither the connection process and handshakes, nor reading the response body is covered in this timeout.","title":"http.timeout"},{"location":"configuration/options/#httpconnection_timeout","text":"Integer, default: 3 Timeout for establishing connections with the upstream in seconds. This includes SSL handshakes. Relay reuses connections when the upstream supports connection keep-alive. Connections are retained for a maximum 75 seconds, or 15 seconds of inactivity.","title":"http.connection_timeout"},{"location":"configuration/options/#httpmax_retry_interval","text":"Integer, default: 60 Maximum interval between failed request retries in seconds.","title":"http.max_retry_interval"},{"location":"configuration/options/#hostheader","text":"string, default: null The custom HTTP Host header to be sent to the upstream.","title":"host.header"},{"location":"configuration/options/#caching","text":"Fine-tune caching of project state.","title":"Caching"},{"location":"configuration/options/#cacheproject_expiry","text":"Integer, default: 300 (5 minutes) The cache timeout for project configurations in seconds. Irrelevant if you use the \"simple proxy mode\", where your project config is stored in local files.","title":"cache.project_expiry"},{"location":"configuration/options/#cacheproject_grace_period","text":"Integer, default: 0 (seconds) Number of seconds to continue using this project configuration after cache expiry while a new state is being fetched. This is added on top of cache.project_expiry and cache.miss_expiry .","title":"cache.project_grace_period"},{"location":"configuration/options/#cacherelay_expiry","text":"Integer, default: 3600 (1 hour) The cache timeout for downstream Relay info (public keys) in seconds. This is only relevant, if you plan to connect further Relays to this one.","title":"cache.relay_expiry"},{"location":"configuration/options/#cacheevent_expiry","text":"Integer, default: 600 (10 minutes) The cache timeout for events (store) before dropping them.","title":"cache.event_expiry"},{"location":"configuration/options/#cachemiss_expiry","text":"Integer, default: 60 (1 minute) The cache timeout for non-existing entries.","title":"cache.miss_expiry"},{"location":"configuration/options/#cachebatch_interval","text":"Integer, default: 100 (100 milliseconds) The buffer timeout for batched queries before sending them upstream in milliseconds .","title":"cache.batch_interval"},{"location":"configuration/options/#cachebatch_size","text":"Integer, default: 500 The maximum number of project configs to fetch from Sentry at once.","title":"cache.batch_size"},{"location":"configuration/options/#cachefile_interval","text":"Integer, default: 10 (10 seconds) Interval for watching local cache override files in seconds.","title":"cache.file_interval"},{"location":"configuration/options/#cacheevent_buffer_size","text":"Integer, default: 1000 The maximum number of events that are buffered in case of network issues or high rates of incoming events.","title":"cache.event_buffer_size"},{"location":"configuration/options/#cacheeviction_interval","text":"Integer, default: 60 (seconds) Interval for evicting outdated project configs from memory.","title":"cache.eviction_interval"},{"location":"configuration/options/#size-limits","text":"Controls various HTTP-related limits. All values are either integers or are human-readable strings of a number and a human-readable unit, such as: 500B 1kB ( 1,000 bytes) 1KB or 1KiB ( 1,024 bytes) 1MB ( 1,000,000 bytes) 1MiB ( 1,048,576 bytes)","title":"Size Limits"},{"location":"configuration/options/#limitsmax_concurrent_requests","text":"Integer, default: 100 The maximum number of concurrent connections to the upstream. If supported by the upstream, Relay supports connection keepalive.","title":"limits.max_concurrent_requests"},{"location":"configuration/options/#limitsmax_concurrent_queries","text":"Integer, default: 5 The maximum number of queries that can be sent concurrently from Relay to the upstream before Relay starts buffering requests. Queries are all requests made to the upstream for obtaining information and explicitly exclude event submission. The concurrency of queries is additionally constrained by max_concurrent_requests .","title":"limits.max_concurrent_queries"},{"location":"configuration/options/#limitsmax_event_size","text":"String, default: 1MiB The maximum payload size for events.","title":"limits.max_event_size"},{"location":"configuration/options/#limitsmax_attachment_size","text":"String, default: 50MiB The maximum size for each attachment.","title":"limits.max_attachment_size"},{"location":"configuration/options/#limitsmax_attachments_size","text":"String, default: 50MiB The maximum combined size for all attachments in an envelope or request.","title":"limits.max_attachments_size"},{"location":"configuration/options/#limitsmax_envelope_size","text":"String, default: 50MiB The maximum payload size for an entire envelopes. Individual limits still apply.","title":"limits.max_envelope_size"},{"location":"configuration/options/#limitsmax_session_count","text":"Integer, default: 100 The maximum number of session items per envelope.","title":"limits.max_session_count"},{"location":"configuration/options/#limitsmax_api_payload_size","text":"String, default: 20MiB The maximum payload size for general API requests.","title":"limits.max_api_payload_size"},{"location":"configuration/options/#limitsmax_api_file_upload_size","text":"String, default: 40MiB The maximum payload size for file uploads and chunks.","title":"limits.max_api_file_upload_size"},{"location":"configuration/options/#limitsmax_api_chunk_upload_size","text":"String, default: 100MiB The maximum payload size for chunks","title":"limits.max_api_chunk_upload_size"},{"location":"configuration/options/#limitsmax_thread_count","text":"Integer, default: number of cpus The maximum number of threads to spawn for CPU and web worker, each. The total number of threads spawned will roughly be 2 * limits.max_thread_count + N , where N is a fixed set of management threads.","title":"limits.max_thread_count"},{"location":"configuration/options/#limitsquery_timeout","text":"Integer, default: 30 (seconds) The maximum number of seconds a query is allowed to take across retries. Individual requests have lower timeouts.","title":"limits.query_timeout"},{"location":"configuration/options/#limitsmax_connection_rate","text":"Integer, default: 256 The maximum number of connections to Relay that can be created at once.","title":"limits.max_connection_rate"},{"location":"configuration/options/#limitsmax_pending_connections","text":"Integer, default: 2048 The maximum number of pending connects to Relay. This corresponds to the backlog param of listen(2) in POSIX.","title":"limits.max_pending_connections"},{"location":"configuration/options/#limitsmax_connections","text":"Integer: default: 25_000 The maximum number of open incoming connections to Relay.","title":"limits.max_connections"},{"location":"configuration/options/#limitsshutdown_timeout","text":"Integer, default:L 10 (seconds) The maximum number of seconds to wait for pending events after receiving a shutdown signal.","title":"limits.shutdown_timeout"},{"location":"configuration/options/#logging","text":"","title":"Logging"},{"location":"configuration/options/#logginglevel","text":"String, default: info The log level for the relay. One of: off error warn info debug trace Warning : On debug and trace levels, Relay emits extremely verbose messages which can have severe impact on application performance.","title":"logging.level"},{"location":"configuration/options/#logginglog_failed_payloads","text":"boolean, default: false Logs full event payloads of failed events to the log stream.","title":"logging.log_failed_payloads"},{"location":"configuration/options/#loggingformat","text":"String, default: auto Controls the log format. One of: auto : Auto detect (pretty for TTY, simplified for other) pretty : Human readable format with colors simplified : Simplified human readable log output json : JSON records, suitable for logging software","title":"logging.format"},{"location":"configuration/options/#loggingenable_backtraces","text":"boolean, default: true Writes back traces for all internal errors to the log stream and includes them in Sentry errors, if enabled.","title":"logging.enable_backtraces"},{"location":"configuration/options/#statsd-metrics","text":"","title":"Statsd Metrics"},{"location":"configuration/options/#metricsstatsd","text":"String, optional If set to a host/port string then metrics will be reported to this statsd instance.","title":"metrics.statsd"},{"location":"configuration/options/#metricsprefix","text":"String, default: sentry.relay The prefix that should be added to all metrics.","title":"metrics.prefix"},{"location":"configuration/options/#metricsdefault_tags","text":"Map of strings to strings, default empty A set of default tags that should be attached to all outgoing statsd metrics.","title":"metrics.default_tags"},{"location":"configuration/options/#metricshostname_tag","text":"String, optional If set, reports the current hostname under the given tag name for all metrics.","title":"metrics.hostname_tag"},{"location":"configuration/options/#internal-error-reporting","text":"Configures error reporting for errors happening within Relay. Disabled by default.","title":"Internal Error Reporting"},{"location":"configuration/options/#sentryenabled","text":"boolean, default: false Whether to report internal errors to a separate DSN. false means no internal errors are sent, but still logged.","title":"sentry.enabled"},{"location":"configuration/options/#sentrydsn","text":"String, optional DSN to report internal Relay failures to. It is not a good idea to set this to a value that will make the Relay send errors to itself. Ideally this should just send errors to Sentry directly, not another Relay.","title":"sentry.dsn"},{"location":"configuration/projects/","text":"Project Configuration In static and proxy mode, you can configure project settings on the file system. Static project configurations are found under the projects subdirectory of the Relay configuration directory, By default, this is located at .relay/projects . To configure projects, add files named <PROJECT_ID>.json in that location: .relay / \u2514\u2500\u2500 projects / \u251c\u2500\u2500 17 .json \u251c\u2500\u2500 21 .json \u2514\u2500\u2500 42 .json Project configurations are an extensible format, mostly consisting of optional fields. The minimal configuration must contain the following fields: { \"slug\" : \"my-project\" , \"publicKeys\" : [ { \"publicKey\" : \"<DSN_KEY>\" , \"isEnabled\" : true } ], \"config\" : { \"allowedDomains\" : [ \"*\" ] } } Note: The public key ( <DSN_KEY> ) is the key of the project's DSN and it has nothing to do with the Relay public key that is used for Relay registration. Basic Options slug { \"slug\" : \"my-project\" } The short name of the project, displayed in Sentry. This value is currently required for Relay to accept events. disabled { \"disabled\" : false } Whether the project is disabled. If set to true , the Relay will drop all events sent to this project. publicKeys { \"publicKeys\" : [ { \"publicKey\" : \"12345abcdb1e4c123490ecec89c1f199\" , \"isEnabled\" : true } ] } A list of known public keys (the public key in a DSN) and whether events using that key should be accepted. You can obtain the key by going into the Sentry > Project Settings > Client Keys (DSN) . The public key can be extracted from the DSN. In the DSN example below: https://12345abcdb1e4c123490ecec89c1f199@o1.ingest.sentry.io/2244 the key is: 12345abcdb1e4c123490ecec89c1f199 A project may contain multiple public keys, only messages using enabled project keys will be processed. Likewise, keys can be disabled using the isEnabled flag. config.allowedDomains { \"config\" : { \"allowedDomains\" : [ \"mycompany.com\" ] } } Configure Origin or Referer URLs which Sentry should accept events from. This is corresponds to the Allowed Domains \"_ setting in the Sentry UI. Warning : An empty list rejects all origins. Use the default [\"*\"] to allow all origins. config.piiConfig { \"config\" : { \"piiConfig\" : { // ... } } } See PII Configuration .","title":"Project Configuration"},{"location":"configuration/projects/#project-configuration","text":"In static and proxy mode, you can configure project settings on the file system. Static project configurations are found under the projects subdirectory of the Relay configuration directory, By default, this is located at .relay/projects . To configure projects, add files named <PROJECT_ID>.json in that location: .relay / \u2514\u2500\u2500 projects / \u251c\u2500\u2500 17 .json \u251c\u2500\u2500 21 .json \u2514\u2500\u2500 42 .json Project configurations are an extensible format, mostly consisting of optional fields. The minimal configuration must contain the following fields: { \"slug\" : \"my-project\" , \"publicKeys\" : [ { \"publicKey\" : \"<DSN_KEY>\" , \"isEnabled\" : true } ], \"config\" : { \"allowedDomains\" : [ \"*\" ] } } Note: The public key ( <DSN_KEY> ) is the key of the project's DSN and it has nothing to do with the Relay public key that is used for Relay registration.","title":"Project Configuration"},{"location":"configuration/projects/#basic-options","text":"","title":"Basic Options"},{"location":"configuration/projects/#slug","text":"{ \"slug\" : \"my-project\" } The short name of the project, displayed in Sentry. This value is currently required for Relay to accept events.","title":"slug"},{"location":"configuration/projects/#disabled","text":"{ \"disabled\" : false } Whether the project is disabled. If set to true , the Relay will drop all events sent to this project.","title":"disabled"},{"location":"configuration/projects/#publickeys","text":"{ \"publicKeys\" : [ { \"publicKey\" : \"12345abcdb1e4c123490ecec89c1f199\" , \"isEnabled\" : true } ] } A list of known public keys (the public key in a DSN) and whether events using that key should be accepted. You can obtain the key by going into the Sentry > Project Settings > Client Keys (DSN) . The public key can be extracted from the DSN. In the DSN example below: https://12345abcdb1e4c123490ecec89c1f199@o1.ingest.sentry.io/2244 the key is: 12345abcdb1e4c123490ecec89c1f199 A project may contain multiple public keys, only messages using enabled project keys will be processed. Likewise, keys can be disabled using the isEnabled flag.","title":"publicKeys"},{"location":"configuration/projects/#configalloweddomains","text":"{ \"config\" : { \"allowedDomains\" : [ \"mycompany.com\" ] } } Configure Origin or Referer URLs which Sentry should accept events from. This is corresponds to the Allowed Domains \"_ setting in the Sentry UI. Warning : An empty list rejects all origins. Use the default [\"*\"] to allow all origins.","title":"config.allowedDomains"},{"location":"configuration/projects/#configpiiconfig","text":"{ \"config\" : { \"piiConfig\" : { // ... } } } See PII Configuration .","title":"config.piiConfig"},{"location":"event-schema/","text":"Event schema This page is intended to eventually replace our current event schema documentation . As opposed to the current one, this one is automatically generated from source code and therefore more likely to be up-to-date and exhaustive. The plan is to eventually make this document the source of truth, i.e. move it into develop.sentry.dev . It is still a work-in-progress. Right now we recommend using our existing docs as linked above and only fall back to this doc to resolve ambiguities. In addition to documentation the event schema is documented in machine-readable form: Download JSON schema (which is what this document is generated from) Event The sentry v7 event structure. Properties: breadcrumbs (optional): null | Breadcrumbs List of breadcrumbs recorded before this event. contexts (optional): { [key: string]: null | ({ [key: string]: any } | DeviceContext | OSContext | RuntimeContext | AppContext | BrowserContext | GPUContext | TraceContext ) } | null Contexts describing the environment (e.g. device, os or browser). culprit (optional): null | string Custom culprit of the event. debug_meta (optional): null | DebugMeta Meta data for event processing and debugging. dist (optional): null | string Program's distribution identifier. The distribution of the application. Distributions are used to disambiguate build or deployment variants of the same release of an application. For example, the dist can be the build number of an XCode build or the version code of an Android build. environment (optional): null | string The environment name, such as production or staging . errors (optional): Array<null | EventProcessingError > | null Errors encountered during processing. Intended to be phased out in favor of annotation/metadata system. event_id (optional): null | string Unique identifier of this event. Hexadecimal string representing a uuid4 value. The length is exactly 32 characters. Dashes are not allowed. Has to be lowercase. Even though this field is backfilled on the server with a new uuid4, it is strongly recommended to generate that uuid4 clientside. There are some features like user feedback which are easier to implement that way, and debugging in case events get lost in your Sentry installation is also easier. Example: json { \"event_id\": \"fc6d8c0c43fc4630ad850ee518f1b9d0\" } exception (optional): null | Exception One or multiple chained (nested) exceptions. extra (optional): { [key: string]: any } | null Arbitrary extra information set by the user. fingerprint (optional): string[] | null Manual fingerprint override. A list of strings used to dictate how this event is supposed to be grouped with other events into issues. For more information about overriding grouping see Customize Grouping with Fingerprints . key_id (optional): null | string Project key which sent this event. level (optional): Level | null Severity level of the event. Defaults to error . logentry (optional): null | LogEntry Custom parameterized message for this event. logger (optional): null | string Logger that created the event. modules (optional): { [key: string]: null | string } | null Name and versions of all installed modules/packages/dependencies in the current environment/application. json { \"django\": \"3.0.0\", \"celery\": \"4.2.1\" } In Python this is a list of installed packages as reported by pkg_resources together with their reported version string. This is primarily used for suggesting to enable certain SDK integrations from within the UI and for making informed decisions on which frameworks to support in future development efforts. platform (optional): null | string Platform identifier of this event (defaults to \"other\"). A string representing the platform the SDK is submitting from. This will be used by the Sentry interface to customize various components in the interface, but also to enter or skip stacktrace processing. Acceptable values are: as3 , c , cfml , cocoa , csharp , elixir , haskell , go , groovy , java , javascript , native , node , objc , other , perl , php , python , ruby project (optional): number | null Project which sent this event. received (optional): null | (number | string) Timestamp when the event has been received by Sentry. release (optional): null | string The release version of the application. Release versions must be unique across all projects in your organization. This value can be the git SHA for the given project, or a product identifier with a semantic version. request (optional): null | Request Information about a web request that occurred during the event. sdk (optional): null | ClientSDKInfo Information about the Sentry SDK that generated this event. server_name (optional): null | string Server or device name the event was generated on. This is supposed to be a hostname. site (optional): null | string Deprecated in favor of tags. spans (optional): Array<null | Span > | null Spans for tracing. stacktrace (optional): null | Stacktrace Event stacktrace. DEPRECATED: Prefer threads or exception depending on which is more appropriate. start_timestamp (optional): null | (number | string) Timestamp when the event has started (relevant for event type = \"transaction\") tags (optional): null | (Array<Array<(null | string)> | null> | { [key: string]: null | string }) Custom tags for this event. A map or list of tags for this event. Each tag must be less than 200 characters. threads (optional): null | Threads Threads that were active when the event occurred. time_spent (optional): number | null Time since the start of the transaction until the error occurred. timestamp (optional): null | (number | string) Timestamp when the event was created. Indicates when the event was created in the Sentry SDK. The format is either a string as defined in RFC 3339 or a numeric (integer or float) value representing the number of seconds that have elapsed since the Unix epoch . Sub-microsecond precision is not preserved with numeric values due to precision limitations with floats (at least in our systems). With that caveat in mind, just send whatever is easiest to produce. All timestamps in the event protocol are formatted this way. json { \"timestamp\": \"2011-05-02T17:41:36Z\" } { \"timestamp\": 1304358096.0 } transaction (optional): null | string Transaction name of the event. For example, in a web app, this might be the route name ( \"/users/<username>/\" or UserView ), in a task queue it might be the function + module name. type (optional): EventType | null Type of event: error, csp, default user (optional): null | User Information about the user who triggered this event. version (optional): null | string Version Breadcrumbs Properties: values : Array<null | Breadcrumb > Breadcrumb The Breadcrumbs Interface specifies a series of application events, or \"breadcrumbs\", that occurred before an event. An event may contain one or more breadcrumbs in an attribute named breadcrumbs . The entries are ordered from oldest to newest. Consequently, the last entry in the list should be the last entry before the event occurred. While breadcrumb attributes are not strictly validated in Sentry, a breadcrumb is most useful when it includes at least a timestamp and type , category or message . The rendering of breadcrumbs in Sentry depends on what is provided. The following example illustrates the breadcrumbs part of the event payload and omits other attributes for simplicity. json { \"breadcrumbs\": { \"values\": [ { \"timestamp\": \"2016-04-20T20:55:53.845Z\", \"message\": \"Something happened\", \"category\": \"log\", \"data\": { \"foo\": \"bar\", \"blub\": \"blah\" } }, { \"timestamp\": \"2016-04-20T20:55:53.847Z\", \"type\": \"navigation\", \"data\": { \"from\": \"/login\", \"to\": \"/dashboard\" } } ] } } Properties: category (optional): null | string A dotted string indicating what the crumb is or from where it comes. Optional. Typically it is a module name or a descriptive string. For instance, ui.click could be used to indicate that a click happened in the UI or flask could be used to indicate that the event originated in the Flask framework. data (optional): { [key: string]: any } | null Arbitrary data associated with this breadcrumb. Contains a dictionary whose contents depend on the breadcrumb type . Additional parameters that are unsupported by the type are rendered as a key/value table. level (optional): Level | null Severity level of the breadcrumb. Optional. Allowed values are, from highest to lowest: fatal , error , warning , info , and debug . Levels are used in the UI to emphasize and deemphasize the crumb. Defaults to info . message (optional): null | string Human readable message for the breadcrumb. If a message is provided, it is rendered as text with all whitespace preserved. Very long text might be truncated in the UI. timestamp (optional): null | (number | string) The timestamp of the breadcrumb. Recommended. A timestamp representing when the breadcrumb occurred. The format is either a string as defined in RFC 3339 or a numeric (integer or float) value representing the number of seconds that have elapsed since the Unix epoch . Breadcrumbs are most useful when they include a timestamp, as it creates a timeline leading up to an event. type (optional): null | string The type of the breadcrumb. Optional , defaults to default . default : Describes a generic breadcrumb. This is typically a log message or user-generated breadcrumb. The data field is entirely undefined and as such, completely rendered as a key/value table. navigation : Describes a navigation breadcrumb. A navigation event can be a URL change in a web application, or a UI transition in a mobile or desktop application, etc. Such a breadcrumb's data object has the required fields from and to , which represent an application route/url each. http : Describes an HTTP request breadcrumb. This represents an HTTP request transmitted from your application. This could be an AJAX request from a web application, or a server-to-server HTTP request to an API service provider, etc. Such a breadcrumb's data property has the fields url , method , status_code (integer) and reason (string). Level Severity level of an event or breadcrumb. Variants: \"debug\" \"error\" \"fatal\" \"info\" \"warning\" DeviceContext Device information. Device context describes the device that caused the event. This is most appropriate for mobile applications. Properties: arch (optional): null | string Native cpu architecture of the device. battery_level (optional): number | null Current battery level in %. If the device has a battery, this can be a floating point value defining the battery level (in the range 0-100). boot_time (optional): null | string Indicator when the device was booted. brand (optional): null | string Brand of the device. charging (optional): boolean | null Whether the device was charging or not. external_free_storage (optional): number | null Free size of the attached external storage in bytes (eg: android SDK card). external_storage_size (optional): number | null Total size of the attached external storage in bytes (eg: android SDK card). family (optional): null | string Family of the device model. This is usually the common part of model names across generations. For instance, iPhone would be a reasonable family, so would be Samsung Galaxy . free_memory (optional): number | null How much memory is still available in bytes. free_storage (optional): number | null How much storage is free in bytes. low_memory (optional): boolean | null Whether the device was low on memory. manufacturer (optional): null | string Manufacturer of the device. memory_size (optional): number | null Total memory available in bytes. model (optional): null | string Device model. This, for example, can be Samsung Galaxy S3 . model_id (optional): null | string Device model (internal identifier). An internal hardware revision to identify the device exactly. name (optional): null | string Name of the device. online (optional): boolean | null Whether the device was online or not. orientation (optional): null | string Current screen orientation. This can be a string portrait or landscape to define the orientation of a device. screen_density (optional): number | null Device screen density. screen_dpi (optional): number | null Screen density as dots-per-inch. screen_resolution (optional): null | string Device screen resolution. (e.g.: 800x600, 3040x1444) simulator (optional): boolean | null Simulator/prod indicator. storage_size (optional): number | null Total storage size of the device in bytes. timezone (optional): null | string Timezone of the device. usable_memory (optional): number | null How much memory is usable for the app in bytes. OSContext Operating system information. OS context describes the operating system on which the event was created. In web contexts, this is the operating system of the browser (generally pulled from the User-Agent string). Properties: build (optional): null | string Internal build number of the operating system. kernel_version (optional): null | string Current kernel version. This is typically the entire output of the uname syscall. name (optional): null | string Name of the operating system. raw_description (optional): null | string Unprocessed operating system info. An unprocessed description string obtained by the operating system. For some well-known runtimes, Sentry will attempt to parse name and version from this string, if they are not explicitly given. rooted (optional): boolean | null Indicator if the OS is rooted (mobile mostly). version (optional): null | string Version of the operating system. RuntimeContext Runtime information. Runtime context describes a runtime in more detail. Typically, this context is present in contexts multiple times if multiple runtimes are involved (for instance, if you have a JavaScript application running on top of JVM). Properties: build (optional): null | string Application build string, if it is separate from the version. name (optional): null | string Runtime name. raw_description (optional): null | string Unprocessed runtime info. An unprocessed description string obtained by the runtime. For some well-known runtimes, Sentry will attempt to parse name and version from this string, if they are not explicitly given. version (optional): null | string Runtime version string. AppContext Application information. App context describes the application. As opposed to the runtime, this is the actual application that was running and carries metadata about the current session. Properties: app_build (optional): null | string Internal build ID as it appears on the platform. app_identifier (optional): null | string Version-independent application identifier, often a dotted bundle ID. app_name (optional): null | string Application name as it appears on the platform. app_start_time (optional): null | string Start time of the app. Formatted UTC timestamp when the user started the application. app_version (optional): null | string Application version as it appears on the platform. build_type (optional): null | string String identifying the kind of build. For example, testflight . device_app_hash (optional): null | string Application-specific device identifier. BrowserContext Web browser information. Properties: name (optional): null | string Display name of the browser application. version (optional): null | string Version string of the browser. GPUContext GPU information. Example: json \"gpu\": { \"name\": \"AMD Radeon Pro 560\", \"vendor_name\": \"Apple\", \"memory_size\": 4096, \"api_type\": \"Metal\", \"multi_threaded_rendering\": true, \"version\": \"Metal\", \"npot_support\": \"Full\" } Properties: api_type (optional): null | string The device low-level API type. Examples: \"Apple Metal\" or \"Direct3D11\" id (optional): any The PCI identifier of the graphics device. memory_size (optional): number | null The total GPU memory available in Megabytes. multi_threaded_rendering (optional): boolean | null Whether the GPU has multi-threaded rendering or not. name (optional): null | string The name of the graphics device. npot_support (optional): null | string The Non-Power-Of-Two support. vendor_id (optional): null | string The PCI vendor identifier of the graphics device. vendor_name (optional): null | string The vendor name as reported by the graphics device. version (optional): null | string The Version of the graphics device. TraceContext Trace context Properties: op (optional): null | string Span type (see OperationType docs). parent_span_id (optional): null | string The ID of the span enclosing this span. span_id : null | string The ID of the span. status : SpanStatus | null Whether the trace failed or succeeded. Currently only used to indicate status of individual transactions. trace_id : null | string The trace ID. SpanStatus Trace status. Values from https://github.com/open-telemetry/opentelemetry-specification/blob/8fb6c14e4709e75a9aaa64b0dbbdf02a6067682a/specification/api-tracing.md#status Mapping to HTTP from https://github.com/open-telemetry/opentelemetry-specification/blob/8fb6c14e4709e75a9aaa64b0dbbdf02a6067682a/specification/data-http.md#status Variants: \"aborted\" \"already_exists\" \"cancelled\" \"data_loss\" \"deadline_exceeded\" \"failed_precondition\" \"internal_error\" \"invalid_argument\" \"not_found\" \"ok\" \"out_of_range\" \"permission_denied\" \"resource_exhausted\" \"unauthenticated\" \"unavailable\" \"unimplemented\" \"unknown\" DebugMeta Debugging and processing meta information. The debug meta interface carries debug information for processing errors and crash reports. Sentry amends the information in this interface. Example (look at field types to see more detail): json { \"debug_meta\": { \"images\": [], \"sdk_info\": { \"sdk_name\": \"iOS\", \"version_major\": 10, \"version_minor\": 3, \"version_patchlevel\": 0 } } } Properties: images (optional): Array<null | ({ [key: string]: any } | AppleDebugImage | NativeDebugImage | ProguardDebugImage )> | null List of debug information files (debug images). sdk_info (optional): null | SystemSDKInfo Information about the system SDK (e.g. iOS SDK). AppleDebugImage Legacy apple debug images (MachO). This was also used for non-apple platforms with similar debug setups. Properties: arch (optional): null | string CPU architecture target. cpu_subtype (optional): number | null MachO CPU subtype identifier. cpu_type (optional): number | null MachO CPU type identifier. image_addr : null | string Starting memory address of the image (required). image_size : number | null Size of the image in bytes (required). image_vmaddr (optional): null | string Loading address in virtual memory. name : null | string Path and name of the debug image (required). uuid : null | string The unique UUID of the image. NativeDebugImage A generic (new-style) native platform debug information file. The type key must be one of: macho - elf : ELF images are used on Linux platforms. Their structure is identical to other native images. - pe Examples: json { \"type\": \"elf\", \"code_id\": \"68220ae2c65d65c1b6aaa12fa6765a6ec2f5f434\", \"code_file\": \"/lib/x86_64-linux-gnu/libgcc_s.so.1\", \"debug_id\": \"e20a2268-5dc6-c165-b6aa-a12fa6765a6e\", \"image_addr\": \"0x7f5140527000\", \"image_size\": 90112, \"image_vmaddr\": \"0x40000\", \"arch\": \"x86_64\" } json { \"type\": \"pe\", \"code_id\": \"57898e12145000\", \"code_file\": \"C:\\\\Windows\\\\System32\\\\dbghelp.dll\", \"debug_id\": \"9c2a902b-6fdf-40ad-8308-588a41d572a0-1\", \"debug_file\": \"dbghelp.pdb\", \"image_addr\": \"0x70850000\", \"image_size\": \"1331200\", \"image_vmaddr\": \"0x40000\", \"arch\": \"x86\" } json { \"type\": \"macho\", \"debug_id\": \"84a04d24-0e60-3810-a8c0-90a65e2df61a\", \"debug_file\": \"libDiagnosticMessagesClient.dylib\", \"code_file\": \"/usr/lib/libDiagnosticMessagesClient.dylib\", \"image_addr\": \"0x7fffe668e000\", \"image_size\": 8192, \"image_vmaddr\": \"0x40000\", \"arch\": \"x86_64\", } Properties: arch (optional): null | string CPU architecture target. Architecture of the module. If missing, this will be backfilled by Sentry. code_file : null | string Path and name of the image file (required). The absolute path to the dynamic library or executable. This helps to locate the file if it is missing on Sentry. pe : The code file should be provided to allow server-side stack walking of binary crash reports, such as Minidumps. code_id (optional): null | string Optional identifier of the code file. elf : If the program was compiled with a relatively recent compiler, this should be the hex representation of the NT_GNU_BUILD_ID program header (type PT_NOTE ), or the value of the .note.gnu.build-id note section (type SHT_NOTE ). Otherwise, leave this value empty. Certain symbol servers use the code identifier to locate debug information for ELF images, in which case this field should be included if possible. pe : Identifier of the executable or DLL. It contains the values of the time_date_stamp from the COFF header and size_of_image from the optional header formatted together into a hex string using %08x%X (note that the second value is not padded): text time_date_stamp: 0x5ab38077 size_of_image: 0x9000 code_id: 5ab380779000 The code identifier should be provided to allow server-side stack walking of binary crash reports, such as Minidumps. macho : Identifier of the dynamic library or executable. It is the value of the LC_UUID load command in the Mach header, formatted as UUID. Can be empty for Mach images, as it is equivalent to the debug identifier. debug_file (optional): null | string Path and name of the debug companion file. elf : Name or absolute path to the file containing stripped debug information for this image. This value might be required to retrieve debug files from certain symbol servers. pe : Name of the PDB file containing debug information for this image. This value is often required to retrieve debug files from specific symbol servers. macho : Name or absolute path to the dSYM file containing debug information for this image. This value might be required to retrieve debug files from certain symbol servers. debug_id : null | string Unique debug identifier of the image. elf : Debug identifier of the dynamic library or executable. If a code identifier is available, the debug identifier is the little-endian UUID representation of the first 16-bytes of that identifier. Spaces are inserted for readability, note the byte order of the first fields: text code id: f1c3bcc0 2798 65fe 3058 404b2831d9e6 4135386c debug id: c0bcc3f1-9827-fe65-3058-404b2831d9e6 If no code id is available, the debug id should be computed by XORing the first 4096 bytes of the .text section in 16-byte chunks, and representing it as a little-endian UUID (again swapping the byte order). pe : signature and age of the PDB file. Both values can be read from the CodeView PDB70 debug information header in the PE. The value should be represented as little-endian UUID, with the age appended at the end. Note that the byte order of the UUID fields must be swapped (spaces inserted for readability): text signature: f1c3bcc0 2798 65fe 3058 404b2831d9e6 age: 1 debug_id: c0bcc3f1-9827-fe65-3058-404b2831d9e6-1 macho : Identifier of the dynamic library or executable. It is the value of the LC_UUID load command in the Mach header, formatted as UUID. image_addr : null | string Starting memory address of the image (required). Memory address, at which the image is mounted in the virtual address space of the process. Should be a string in hex representation prefixed with \"0x\" . image_size : number | null Size of the image in bytes (required). The size of the image in virtual memory. If missing, Sentry will assume that the image spans up to the next image, which might lead to invalid stack traces. image_vmaddr (optional): null | string Loading address in virtual memory. Preferred load address of the image in virtual memory, as declared in the headers of the image. When loading an image, the operating system may still choose to place it at a different address. Symbols and addresses in the native image are always relative to the start of the image and do not consider the preferred load address. It is merely a hint to the loader. elf / macho : If this value is non-zero, all symbols and addresses declared in the native image start at this address, rather than 0. By contrast, Sentry deals with addresses relative to the start of the image. For example, with image_vmaddr: 0x40000 , a symbol located at 0x401000 has a relative address of 0x1000 . Relative addresses used in Apple Crash Reports and addr2line are usually in the preferred address space, and not relative address space. ProguardDebugImage Proguard mapping file. Proguard images refer to mapping.txt files generated when Proguard obfuscates function names. The Java SDK integrations assign this file a unique identifier, which has to be included in the list of images. Properties: uuid : null | string UUID computed from the file contents, assigned by the Java SDK. SystemSDKInfo Holds information about the system SDK. This is relevant for iOS and other platforms that have a system SDK. Not to be confused with the client SDK. Properties: sdk_name (optional): null | string The internal name of the SDK. version_major (optional): number | null The major version of the SDK as integer or 0. version_minor (optional): number | null The minor version of the SDK as integer or 0. version_patchlevel (optional): number | null The patch version of the SDK as integer or 0. EventProcessingError An event processing error. Properties: name (optional): null | string Affected key or deep path. type : null | string The error kind. value (optional): any The original value causing this error. Exception Properties: values : Array<null | ValueObject > ValueObject A single exception. Multiple values inside of an event represent chained exceptions and should be sorted oldest to newest. For example, consider this Python code snippet: python try: raise Exception(\"random boring invariant was not met!\") except Exception as e: raise ValueError(\"something went wrong, help!\") from e Exception would be described first in the values list, followed by a description of ValueError : json { \"exception\": { \"values\": [ {\"type\": \"Exception\": \"value\": \"random boring invariant was not met!\"}, {\"type\": \"ValueError\", \"value\": \"something went wrong, help!\"}, ] } } Properties: mechanism (optional): null | Mechanism Mechanism by which this exception was generated and handled. module (optional): null | string The optional module, or package which the exception type lives in. stacktrace (optional): null | Stacktrace Stack trace containing frames of this exception. thread_id (optional): null | (number | string) An optional value which refers to a thread . type (optional): null | string Exception type, e.g. ValueError . At least one of type or value is required, otherwise the exception is discarded. value (optional): null | string Human readable display value. At least one of type or value is required, otherwise the exception is discarded. Mechanism The mechanism by which an exception was generated and handled. The exception mechanism is an optional field residing in the exception . It carries additional information about the way the exception was created on the target system. This includes general exception values obtained from the operating system or runtime APIs, as well as mechanism-specific values. Properties: data (optional): { [key: string]: any } | null Additional attributes depending on the mechanism type. description (optional): null | string Optional human-readable description of the error mechanism. May include a possible hint on how to solve this error. handled (optional): boolean | null Flag indicating whether this exception was handled. This is a best-effort guess at whether the exception was handled by user code or not. For example: Exceptions leading to a 500 Internal Server Error or to a hard process crash are handled=false , as the SDK typically has an integration that automatically captures the error. Exceptions captured using capture_exception (called from user code) are handled=true as the user explicitly captured the exception (and therefore kind of handled it) help_link (optional): null | string Link to online resources describing this error. meta (optional): null | MechanismMeta Operating system or runtime meta information. synthetic (optional): boolean | null If this is set then the exception is not a real exception but some form of synthetic error for instance from a signal handler, a hard segfault or similar where type and value are not useful for grouping or display purposes. type : null | string Mechanism type (required). Required unique identifier of this mechanism determining rendering and processing of the mechanism data. In the Python SDK this is merely the name of the framework integration that produced the exception, while for native it is e.g. \"minidump\" or \"applecrashreport\" . MechanismMeta Operating system or runtime meta information to an exception mechanism. The mechanism metadata usually carries error codes reported by the runtime or operating system, along with a platform-dependent interpretation of these codes. SDKs can safely omit code names and descriptions for well-known error codes, as it will be filled out by Sentry. For proprietary or vendor-specific error codes, adding these values will give additional information to the user. Properties: errno (optional): null | CError Optional ISO C standard error code. mach_exception (optional): null | MachException A Mach Exception on Apple systems comprising a code triple and optional descriptions. signal (optional): null | POSIXSignal Information on the POSIX signal. CError POSIX signal with optional extended data. Error codes set by Linux system calls and some library functions as specified in ISO C99, POSIX.1-2001, and POSIX.1-2008. See errno(3) for more information. Properties: name (optional): null | string Optional name of the errno constant. number (optional): number | null The error code as specified by ISO C99, POSIX.1-2001 or POSIX.1-2008. MachException Mach exception information. Properties: code (optional): number | null The mach exception code. exception (optional): number | null The mach exception type. name (optional): null | string Optional name of the mach exception. subcode (optional): number | null The mach exception subcode. POSIXSignal POSIX signal with optional extended data. On Apple systems, signals also carry a code in addition to the signal number describing the signal in more detail. On Linux, this code does not exist. Properties: code (optional): number | null An optional signal code present on Apple systems. code_name (optional): null | string Optional name of the errno constant. name (optional): null | string Optional name of the errno constant. number (optional): number | null The POSIX signal number. Stacktrace A stack trace of a single thread. A stack trace contains a list of frames, each with various bits (most optional) describing the context of that frame. Frames should be sorted from oldest to newest. For the given example program written in Python: ```python def foo(): my_var = 'foo' raise ValueError() def main(): foo() ``` A minimalistic stack trace for the above program in the correct order: json { \"frames\": [ {\"function\": \"main\"}, {\"function\": \"foo\"} ] } The top frame fully symbolicated with five lines of source context: json { \"frames\": [{ \"in_app\": true, \"function\": \"myfunction\", \"abs_path\": \"/real/file/name.py\", \"filename\": \"file/name.py\", \"lineno\": 3, \"vars\": { \"my_var\": \"'value'\" }, \"pre_context\": [ \"def foo():\", \" my_var = 'foo'\", ], \"context_line\": \" raise ValueError()\", \"post_context\": [ \"\", \"def main():\" ], }] } A minimal native stack trace with register values. Note that the package event attribute must be \"native\" for these frames to be symbolicated. json { \"frames\": [ {\"instruction_addr\": \"0x7fff5bf3456c\"}, {\"instruction_addr\": \"0x7fff5bf346c0\"}, ], \"registers\": { \"rip\": \"0x00007ff6eef54be2\", \"rsp\": \"0x0000003b710cd9e0\" } } Properties: frames : Array<null | Frame > | null Required. A non-empty list of stack frames. The list is ordered from caller to callee, or oldest to youngest. The last frame is the one creating the exception. lang (optional): null | string The language of the stacktrace. registers (optional): { [key: string]: null | string } | null Register values of the thread (top frame). A map of register names and their values. The values should contain the actual register values of the thread, thus mapping to the last frame in the list. Frame Holds information about a single stacktrace frame. Each object should contain at least a filename , function or instruction_addr attribute. All values are optional, but recommended. Properties: abs_path (optional): null | string Absolute path to the source file. colno (optional): number | null Column number within the source file, starting at 1. context_line (optional): null | string Source code of the current line ( lineno ). filename (optional): null | string The source file name (basename only). function (optional): null | string Name of the frame's function. This might include the name of a class. This function name may be shortened or demangled. If not, Sentry will demangle and shorten it for some platforms. The original function name will be stored in raw_function . image_addr (optional): null | string (C/C++/Native) Start address of the containing code module (image). in_app (optional): boolean | null Override whether this frame should be considered part of application code, or part of libraries/frameworks/dependencies. Setting this attribute to false causes the frame to be hidden/collapsed by default and mostly ignored during issue grouping. instruction_addr (optional): null | string (C/C++/Native) Absolute address of the frame's CPU instruction. lineno (optional): number | null Line number within the source file, starting at 1. module (optional): null | string Name of the module the frame is contained in. Note that this might also include a class name if that is something the language natively considers to be part of the stack (for instance in Java). package (optional): null | string Name of the package that contains the frame. For instance this can be a dylib for native languages, the name of the jar or .NET assembly. platform (optional): null | string Which platform this frame is from. This can override the platform for a single frame. Otherwise, the platform of the event is assumed. This can be used for multi-platform stack traces, such as in React Native. post_context (optional): Array<null | string> | null Source code of the lines after lineno . pre_context (optional): Array<null | string> | null Source code leading up to lineno . raw_function (optional): null | string A raw (but potentially truncated) function value. The original function name, if the function name is shortened or demangled. Sentry shows the raw function when clicking on the shortened one in the UI. If this has the same value as function it's best to be omitted. This exists because on many platforms the function itself contains additional information like overload specifies or a lot of generics which can make it exceed the maximum limit we provide for the field. In those cases then we cannot reliably trim down the function any more at a later point because the more valuable information has been removed. The logic to be applied is that an intelligently trimmed function name should be stored in function and the value before trimming is stored in this field instead. However also this field will be capped at 256 characters at the moment which often means that not the entire original value can be stored. symbol (optional): null | string Potentially mangled name of the symbol as it appears in an executable. This is different from a function name by generally being the mangled name that appears natively in the binary. This is relevant for languages like Swift, C++ or Rust. symbol_addr (optional): null | string (C/C++/Native) Start address of the frame's function. vars (optional): { [key: string]: any } | null Mapping of local variables and expression names that were available in this frame. LogEntry A log entry message. A log message is similar to the message attribute on the event itself but can additionally hold optional parameters. json { \"message\": { \"message\": \"My raw message with interpreted strings like %s\", \"params\": [\"this\"] } } json { \"message\": { \"message\": \"My raw message with interpreted strings like {foo}\", \"params\": {\"foo\": \"this\"} } } Properties: formatted (optional): null | string The formatted message. If message and params are given, Sentry will attempt to backfill formatted if empty. It must not exceed 8192 characters. Longer messages will be truncated. message (optional): null | string The log message with parameter placeholders. This attribute is primarily used for grouping related events together into issues. Therefore this really should just be a string template, i.e. Sending %d requests instead of Sending 9999 requests . The latter is much better at home in formatted . It must not exceed 8192 characters. Longer messages will be truncated. params (optional): any Parameters to be interpolated into the log message. This can be an array of positional parameters as well as a mapping of named arguments to their values. Request Http request information. The Request interface contains information on a HTTP request related to the event. In client SDKs, this can be an outgoing request, or the request that rendered the current web page. On server SDKs, this could be the incoming web request that is being handled. The data variable should only contain the request body (not the query string). It can either be a dictionary (for standard HTTP requests) or a raw request body. Ordered Maps In the Request interface, several attributes can either be declared as string, object, or list of tuples. Sentry attempts to parse structured information from the string representation in such cases. Sometimes, keys can be declared multiple times, or the order of elements matters. In such cases, use the tuple representation over a plain object. Example of request headers as object: json { \"content-type\": \"application/json\", \"accept\": \"application/json, application/xml\" } Example of the same headers as list of tuples: json [ [\"content-type\", \"application/json\"], [\"accept\", \"application/json\"], [\"accept\", \"application/xml\"] ] Example of a fully populated request object: json { \"request\": { \"method\": \"POST\", \"url\": \"http://absolute.uri/foo\", \"query_string\": \"query=foobar&page=2\", \"data\": { \"foo\": \"bar\" }, \"cookies\": \"PHPSESSID=298zf09hf012fh2; csrftoken=u32t4o3tb3gg43; _gat=1;\", \"headers\": { \"content-type\": \"text/html\" }, \"env\": { \"REMOTE_ADDR\": \"192.168.0.1\" } } } Properties: cookies (optional): null | (Array<Array<(null | string)> | null> | { [key: string]: null | string }) The cookie values. Can be given unparsed as string, as dictionary, or as a list of tuples. data (optional): any Request data in any format that makes sense. SDKs should discard large and binary bodies by default. Can be given as string or structural data of any format. env (optional): { [key: string]: any } | null Server environment data, such as CGI/WSGI. A dictionary containing environment information passed from the server. This is where information such as CGI/WSGI/Rack keys go that are not HTTP headers. Sentry will explicitly look for REMOTE_ADDR to extract an IP address. fragment (optional): null | string The fragment of the request URL. headers (optional): null | (Array<Array<(null | string)> | null> | { [key: string]: null | string }) A dictionary of submitted headers. If a header appears multiple times it, needs to be merged according to the HTTP standard for header merging. Header names are treated case-insensitively by Sentry. inferred_content_type (optional): null | string The inferred content type of the request payload. method (optional): null | string HTTP request method. query_string (optional): null | (Array<Array<(null | string)> | null> | { [key: string]: null | string }) The query string component of the URL. Can be given as unparsed string, dictionary, or list of tuples. If the query string is not declared and part of the url , Sentry moves it to the query string. url (optional): null | string The URL of the request if available. The query string can be declared either as part of the url , or separately in query_string . ClientSDKInfo The SDK Interface describes the Sentry SDK and its configuration used to capture and transmit an event. Properties: integrations (optional): Array<null | string> | null List of integrations that are enabled in the SDK. Optional. The list should have all enabled integrations, including default integrations. Default integrations are included because different SDK releases may contain different default integrations. name : null | string Unique SDK name. Required. The name of the SDK. The format is entity.ecosystem[.flavor] where entity identifies the developer of the SDK, ecosystem refers to the programming language or platform where the SDK is to be used and the optional flavor is used to identify standalone SDKs that are part of a major ecosystem. Official Sentry SDKs use the entity sentry , as in sentry.python or sentry.javascript.react-native . Please use a different entity for your own SDKs. packages (optional): Array<null | ClientSDKPackage > | null List of installed and loaded SDK packages. Optional. A list of packages that were installed as part of this SDK or the activated integrations. Each package consists of a name in the format source:identifier and version . If the source is a Git repository, the source should be git , the identifier should be a checkout link and the version should be a Git reference (branch, tag or SHA). version : null | string The version of the SDK. Required. It should have the Semantic Versioning format MAJOR.MINOR.PATCH , without any prefix (no v or anything else in front of the major version number). Examples: 0.1.0 , 1.0.0 , 4.3.12 ClientSDKPackage An installed and loaded package as part of the Sentry SDK. Properties: name (optional): null | string Name of the package. version (optional): null | string Version of the package. Span Properties: description (optional): null | string Human readable description of a span (e.g. method URL). op (optional): null | string Span type (see OperationType docs). parent_span_id (optional): null | string The ID of the span enclosing this span. span_id : null | string The Span id. start_timestamp : null | (number | string) Timestamp when the span started. status (optional): SpanStatus | null The status of a span timestamp : null | (number | string) Timestamp when the span was ended. trace_id : null | string The ID of the trace the span belongs to. Threads Properties: values : Array<null | Thread > Thread A process thread of an event. The Threads Interface specifies threads that were running at the time an event happened. These threads can also contain stack traces. An event may contain one or more threads in an attribute named threads . The following example illustrates the threads part of the event payload and omits other attributes for simplicity. json { \"threads\": { \"values\": [ { \"id\": \"0\", \"name\": \"main\", \"crashed\": true, \"stacktrace\": {} } ] } } Properties: crashed (optional): boolean | null A flag indicating whether the thread crashed. Defaults to false . current (optional): boolean | null A flag indicating whether the thread was in the foreground. Defaults to false . id (optional): null | (number | string) The ID of the thread. Typically a number or numeric string. Needs to be unique among the threads. An exception can set the thread_id attribute to cross-reference this thread. name (optional): null | string Display name of this thread. stacktrace (optional): null | Stacktrace Stack trace containing frames of this exception. The thread that crashed with an exception should not have a stack trace, but instead, the thread_id attribute should be set on the exception and Sentry will connect the two. EventType The type of an event. Variants: \"csp\" \"default\" \"error\" \"expectct\" \"expectstaple\" \"hpkp\" \"transaction\" User Information about the user who triggered an event. json { \"user\": { \"id\": \"unique_id\", \"username\": \"my_user\", \"email\": \"foo@example.com\", \"ip_address\": \"127.0.0.1\", \"subscription\": \"basic\" } } Properties: data (optional): { [key: string]: any } | null Additional arbitrary fields, as stored in the database (and sometimes as sent by clients). All data from self.other should end up here after store normalization. email (optional): null | string Email address of the user. geo (optional): null | Geo Approximate geographical location of the end user or device. id (optional): null | string Unique identifier of the user. ip_address (optional): null | string Remote IP address of the user. Defaults to \"\". name (optional): null | string Human readable name of the user. username (optional): null | string Username of the user. Geo Geographical location of the end user or device. Properties: city (optional): null | string Human readable city name. country_code (optional): null | string Two-letter country code (ISO 3166-1 alpha-2). region (optional): null | string Human readable region name or code.","title":""},{"location":"event-schema/#event-schema","text":"This page is intended to eventually replace our current event schema documentation . As opposed to the current one, this one is automatically generated from source code and therefore more likely to be up-to-date and exhaustive. The plan is to eventually make this document the source of truth, i.e. move it into develop.sentry.dev . It is still a work-in-progress. Right now we recommend using our existing docs as linked above and only fall back to this doc to resolve ambiguities. In addition to documentation the event schema is documented in machine-readable form: Download JSON schema (which is what this document is generated from)","title":"Event schema"},{"location":"event-schema/#event","text":"The sentry v7 event structure. Properties: breadcrumbs (optional): null | Breadcrumbs List of breadcrumbs recorded before this event. contexts (optional): { [key: string]: null | ({ [key: string]: any } | DeviceContext | OSContext | RuntimeContext | AppContext | BrowserContext | GPUContext | TraceContext ) } | null Contexts describing the environment (e.g. device, os or browser). culprit (optional): null | string Custom culprit of the event. debug_meta (optional): null | DebugMeta Meta data for event processing and debugging. dist (optional): null | string Program's distribution identifier. The distribution of the application. Distributions are used to disambiguate build or deployment variants of the same release of an application. For example, the dist can be the build number of an XCode build or the version code of an Android build. environment (optional): null | string The environment name, such as production or staging . errors (optional): Array<null | EventProcessingError > | null Errors encountered during processing. Intended to be phased out in favor of annotation/metadata system. event_id (optional): null | string Unique identifier of this event. Hexadecimal string representing a uuid4 value. The length is exactly 32 characters. Dashes are not allowed. Has to be lowercase. Even though this field is backfilled on the server with a new uuid4, it is strongly recommended to generate that uuid4 clientside. There are some features like user feedback which are easier to implement that way, and debugging in case events get lost in your Sentry installation is also easier. Example: json { \"event_id\": \"fc6d8c0c43fc4630ad850ee518f1b9d0\" } exception (optional): null | Exception One or multiple chained (nested) exceptions. extra (optional): { [key: string]: any } | null Arbitrary extra information set by the user. fingerprint (optional): string[] | null Manual fingerprint override. A list of strings used to dictate how this event is supposed to be grouped with other events into issues. For more information about overriding grouping see Customize Grouping with Fingerprints . key_id (optional): null | string Project key which sent this event. level (optional): Level | null Severity level of the event. Defaults to error . logentry (optional): null | LogEntry Custom parameterized message for this event. logger (optional): null | string Logger that created the event. modules (optional): { [key: string]: null | string } | null Name and versions of all installed modules/packages/dependencies in the current environment/application. json { \"django\": \"3.0.0\", \"celery\": \"4.2.1\" } In Python this is a list of installed packages as reported by pkg_resources together with their reported version string. This is primarily used for suggesting to enable certain SDK integrations from within the UI and for making informed decisions on which frameworks to support in future development efforts. platform (optional): null | string Platform identifier of this event (defaults to \"other\"). A string representing the platform the SDK is submitting from. This will be used by the Sentry interface to customize various components in the interface, but also to enter or skip stacktrace processing. Acceptable values are: as3 , c , cfml , cocoa , csharp , elixir , haskell , go , groovy , java , javascript , native , node , objc , other , perl , php , python , ruby project (optional): number | null Project which sent this event. received (optional): null | (number | string) Timestamp when the event has been received by Sentry. release (optional): null | string The release version of the application. Release versions must be unique across all projects in your organization. This value can be the git SHA for the given project, or a product identifier with a semantic version. request (optional): null | Request Information about a web request that occurred during the event. sdk (optional): null | ClientSDKInfo Information about the Sentry SDK that generated this event. server_name (optional): null | string Server or device name the event was generated on. This is supposed to be a hostname. site (optional): null | string Deprecated in favor of tags. spans (optional): Array<null | Span > | null Spans for tracing. stacktrace (optional): null | Stacktrace Event stacktrace. DEPRECATED: Prefer threads or exception depending on which is more appropriate. start_timestamp (optional): null | (number | string) Timestamp when the event has started (relevant for event type = \"transaction\") tags (optional): null | (Array<Array<(null | string)> | null> | { [key: string]: null | string }) Custom tags for this event. A map or list of tags for this event. Each tag must be less than 200 characters. threads (optional): null | Threads Threads that were active when the event occurred. time_spent (optional): number | null Time since the start of the transaction until the error occurred. timestamp (optional): null | (number | string) Timestamp when the event was created. Indicates when the event was created in the Sentry SDK. The format is either a string as defined in RFC 3339 or a numeric (integer or float) value representing the number of seconds that have elapsed since the Unix epoch . Sub-microsecond precision is not preserved with numeric values due to precision limitations with floats (at least in our systems). With that caveat in mind, just send whatever is easiest to produce. All timestamps in the event protocol are formatted this way. json { \"timestamp\": \"2011-05-02T17:41:36Z\" } { \"timestamp\": 1304358096.0 } transaction (optional): null | string Transaction name of the event. For example, in a web app, this might be the route name ( \"/users/<username>/\" or UserView ), in a task queue it might be the function + module name. type (optional): EventType | null Type of event: error, csp, default user (optional): null | User Information about the user who triggered this event. version (optional): null | string Version","title":"Event"},{"location":"event-schema/#breadcrumbs","text":"Properties: values : Array<null | Breadcrumb >","title":"Breadcrumbs"},{"location":"event-schema/#breadcrumb","text":"The Breadcrumbs Interface specifies a series of application events, or \"breadcrumbs\", that occurred before an event. An event may contain one or more breadcrumbs in an attribute named breadcrumbs . The entries are ordered from oldest to newest. Consequently, the last entry in the list should be the last entry before the event occurred. While breadcrumb attributes are not strictly validated in Sentry, a breadcrumb is most useful when it includes at least a timestamp and type , category or message . The rendering of breadcrumbs in Sentry depends on what is provided. The following example illustrates the breadcrumbs part of the event payload and omits other attributes for simplicity. json { \"breadcrumbs\": { \"values\": [ { \"timestamp\": \"2016-04-20T20:55:53.845Z\", \"message\": \"Something happened\", \"category\": \"log\", \"data\": { \"foo\": \"bar\", \"blub\": \"blah\" } }, { \"timestamp\": \"2016-04-20T20:55:53.847Z\", \"type\": \"navigation\", \"data\": { \"from\": \"/login\", \"to\": \"/dashboard\" } } ] } } Properties: category (optional): null | string A dotted string indicating what the crumb is or from where it comes. Optional. Typically it is a module name or a descriptive string. For instance, ui.click could be used to indicate that a click happened in the UI or flask could be used to indicate that the event originated in the Flask framework. data (optional): { [key: string]: any } | null Arbitrary data associated with this breadcrumb. Contains a dictionary whose contents depend on the breadcrumb type . Additional parameters that are unsupported by the type are rendered as a key/value table. level (optional): Level | null Severity level of the breadcrumb. Optional. Allowed values are, from highest to lowest: fatal , error , warning , info , and debug . Levels are used in the UI to emphasize and deemphasize the crumb. Defaults to info . message (optional): null | string Human readable message for the breadcrumb. If a message is provided, it is rendered as text with all whitespace preserved. Very long text might be truncated in the UI. timestamp (optional): null | (number | string) The timestamp of the breadcrumb. Recommended. A timestamp representing when the breadcrumb occurred. The format is either a string as defined in RFC 3339 or a numeric (integer or float) value representing the number of seconds that have elapsed since the Unix epoch . Breadcrumbs are most useful when they include a timestamp, as it creates a timeline leading up to an event. type (optional): null | string The type of the breadcrumb. Optional , defaults to default . default : Describes a generic breadcrumb. This is typically a log message or user-generated breadcrumb. The data field is entirely undefined and as such, completely rendered as a key/value table. navigation : Describes a navigation breadcrumb. A navigation event can be a URL change in a web application, or a UI transition in a mobile or desktop application, etc. Such a breadcrumb's data object has the required fields from and to , which represent an application route/url each. http : Describes an HTTP request breadcrumb. This represents an HTTP request transmitted from your application. This could be an AJAX request from a web application, or a server-to-server HTTP request to an API service provider, etc. Such a breadcrumb's data property has the fields url , method , status_code (integer) and reason (string).","title":"Breadcrumb"},{"location":"event-schema/#level","text":"Severity level of an event or breadcrumb. Variants: \"debug\" \"error\" \"fatal\" \"info\" \"warning\"","title":"Level"},{"location":"event-schema/#devicecontext","text":"Device information. Device context describes the device that caused the event. This is most appropriate for mobile applications. Properties: arch (optional): null | string Native cpu architecture of the device. battery_level (optional): number | null Current battery level in %. If the device has a battery, this can be a floating point value defining the battery level (in the range 0-100). boot_time (optional): null | string Indicator when the device was booted. brand (optional): null | string Brand of the device. charging (optional): boolean | null Whether the device was charging or not. external_free_storage (optional): number | null Free size of the attached external storage in bytes (eg: android SDK card). external_storage_size (optional): number | null Total size of the attached external storage in bytes (eg: android SDK card). family (optional): null | string Family of the device model. This is usually the common part of model names across generations. For instance, iPhone would be a reasonable family, so would be Samsung Galaxy . free_memory (optional): number | null How much memory is still available in bytes. free_storage (optional): number | null How much storage is free in bytes. low_memory (optional): boolean | null Whether the device was low on memory. manufacturer (optional): null | string Manufacturer of the device. memory_size (optional): number | null Total memory available in bytes. model (optional): null | string Device model. This, for example, can be Samsung Galaxy S3 . model_id (optional): null | string Device model (internal identifier). An internal hardware revision to identify the device exactly. name (optional): null | string Name of the device. online (optional): boolean | null Whether the device was online or not. orientation (optional): null | string Current screen orientation. This can be a string portrait or landscape to define the orientation of a device. screen_density (optional): number | null Device screen density. screen_dpi (optional): number | null Screen density as dots-per-inch. screen_resolution (optional): null | string Device screen resolution. (e.g.: 800x600, 3040x1444) simulator (optional): boolean | null Simulator/prod indicator. storage_size (optional): number | null Total storage size of the device in bytes. timezone (optional): null | string Timezone of the device. usable_memory (optional): number | null How much memory is usable for the app in bytes.","title":"DeviceContext"},{"location":"event-schema/#oscontext","text":"Operating system information. OS context describes the operating system on which the event was created. In web contexts, this is the operating system of the browser (generally pulled from the User-Agent string). Properties: build (optional): null | string Internal build number of the operating system. kernel_version (optional): null | string Current kernel version. This is typically the entire output of the uname syscall. name (optional): null | string Name of the operating system. raw_description (optional): null | string Unprocessed operating system info. An unprocessed description string obtained by the operating system. For some well-known runtimes, Sentry will attempt to parse name and version from this string, if they are not explicitly given. rooted (optional): boolean | null Indicator if the OS is rooted (mobile mostly). version (optional): null | string Version of the operating system.","title":"OSContext"},{"location":"event-schema/#runtimecontext","text":"Runtime information. Runtime context describes a runtime in more detail. Typically, this context is present in contexts multiple times if multiple runtimes are involved (for instance, if you have a JavaScript application running on top of JVM). Properties: build (optional): null | string Application build string, if it is separate from the version. name (optional): null | string Runtime name. raw_description (optional): null | string Unprocessed runtime info. An unprocessed description string obtained by the runtime. For some well-known runtimes, Sentry will attempt to parse name and version from this string, if they are not explicitly given. version (optional): null | string Runtime version string.","title":"RuntimeContext"},{"location":"event-schema/#appcontext","text":"Application information. App context describes the application. As opposed to the runtime, this is the actual application that was running and carries metadata about the current session. Properties: app_build (optional): null | string Internal build ID as it appears on the platform. app_identifier (optional): null | string Version-independent application identifier, often a dotted bundle ID. app_name (optional): null | string Application name as it appears on the platform. app_start_time (optional): null | string Start time of the app. Formatted UTC timestamp when the user started the application. app_version (optional): null | string Application version as it appears on the platform. build_type (optional): null | string String identifying the kind of build. For example, testflight . device_app_hash (optional): null | string Application-specific device identifier.","title":"AppContext"},{"location":"event-schema/#browsercontext","text":"Web browser information. Properties: name (optional): null | string Display name of the browser application. version (optional): null | string Version string of the browser.","title":"BrowserContext"},{"location":"event-schema/#gpucontext","text":"GPU information. Example: json \"gpu\": { \"name\": \"AMD Radeon Pro 560\", \"vendor_name\": \"Apple\", \"memory_size\": 4096, \"api_type\": \"Metal\", \"multi_threaded_rendering\": true, \"version\": \"Metal\", \"npot_support\": \"Full\" } Properties: api_type (optional): null | string The device low-level API type. Examples: \"Apple Metal\" or \"Direct3D11\" id (optional): any The PCI identifier of the graphics device. memory_size (optional): number | null The total GPU memory available in Megabytes. multi_threaded_rendering (optional): boolean | null Whether the GPU has multi-threaded rendering or not. name (optional): null | string The name of the graphics device. npot_support (optional): null | string The Non-Power-Of-Two support. vendor_id (optional): null | string The PCI vendor identifier of the graphics device. vendor_name (optional): null | string The vendor name as reported by the graphics device. version (optional): null | string The Version of the graphics device.","title":"GPUContext"},{"location":"event-schema/#tracecontext","text":"Trace context Properties: op (optional): null | string Span type (see OperationType docs). parent_span_id (optional): null | string The ID of the span enclosing this span. span_id : null | string The ID of the span. status : SpanStatus | null Whether the trace failed or succeeded. Currently only used to indicate status of individual transactions. trace_id : null | string The trace ID.","title":"TraceContext"},{"location":"event-schema/#spanstatus","text":"Trace status. Values from https://github.com/open-telemetry/opentelemetry-specification/blob/8fb6c14e4709e75a9aaa64b0dbbdf02a6067682a/specification/api-tracing.md#status Mapping to HTTP from https://github.com/open-telemetry/opentelemetry-specification/blob/8fb6c14e4709e75a9aaa64b0dbbdf02a6067682a/specification/data-http.md#status Variants: \"aborted\" \"already_exists\" \"cancelled\" \"data_loss\" \"deadline_exceeded\" \"failed_precondition\" \"internal_error\" \"invalid_argument\" \"not_found\" \"ok\" \"out_of_range\" \"permission_denied\" \"resource_exhausted\" \"unauthenticated\" \"unavailable\" \"unimplemented\" \"unknown\"","title":"SpanStatus"},{"location":"event-schema/#debugmeta","text":"Debugging and processing meta information. The debug meta interface carries debug information for processing errors and crash reports. Sentry amends the information in this interface. Example (look at field types to see more detail): json { \"debug_meta\": { \"images\": [], \"sdk_info\": { \"sdk_name\": \"iOS\", \"version_major\": 10, \"version_minor\": 3, \"version_patchlevel\": 0 } } } Properties: images (optional): Array<null | ({ [key: string]: any } | AppleDebugImage | NativeDebugImage | ProguardDebugImage )> | null List of debug information files (debug images). sdk_info (optional): null | SystemSDKInfo Information about the system SDK (e.g. iOS SDK).","title":"DebugMeta"},{"location":"event-schema/#appledebugimage","text":"Legacy apple debug images (MachO). This was also used for non-apple platforms with similar debug setups. Properties: arch (optional): null | string CPU architecture target. cpu_subtype (optional): number | null MachO CPU subtype identifier. cpu_type (optional): number | null MachO CPU type identifier. image_addr : null | string Starting memory address of the image (required). image_size : number | null Size of the image in bytes (required). image_vmaddr (optional): null | string Loading address in virtual memory. name : null | string Path and name of the debug image (required). uuid : null | string The unique UUID of the image.","title":"AppleDebugImage"},{"location":"event-schema/#nativedebugimage","text":"A generic (new-style) native platform debug information file. The type key must be one of: macho - elf : ELF images are used on Linux platforms. Their structure is identical to other native images. - pe Examples: json { \"type\": \"elf\", \"code_id\": \"68220ae2c65d65c1b6aaa12fa6765a6ec2f5f434\", \"code_file\": \"/lib/x86_64-linux-gnu/libgcc_s.so.1\", \"debug_id\": \"e20a2268-5dc6-c165-b6aa-a12fa6765a6e\", \"image_addr\": \"0x7f5140527000\", \"image_size\": 90112, \"image_vmaddr\": \"0x40000\", \"arch\": \"x86_64\" } json { \"type\": \"pe\", \"code_id\": \"57898e12145000\", \"code_file\": \"C:\\\\Windows\\\\System32\\\\dbghelp.dll\", \"debug_id\": \"9c2a902b-6fdf-40ad-8308-588a41d572a0-1\", \"debug_file\": \"dbghelp.pdb\", \"image_addr\": \"0x70850000\", \"image_size\": \"1331200\", \"image_vmaddr\": \"0x40000\", \"arch\": \"x86\" } json { \"type\": \"macho\", \"debug_id\": \"84a04d24-0e60-3810-a8c0-90a65e2df61a\", \"debug_file\": \"libDiagnosticMessagesClient.dylib\", \"code_file\": \"/usr/lib/libDiagnosticMessagesClient.dylib\", \"image_addr\": \"0x7fffe668e000\", \"image_size\": 8192, \"image_vmaddr\": \"0x40000\", \"arch\": \"x86_64\", } Properties: arch (optional): null | string CPU architecture target. Architecture of the module. If missing, this will be backfilled by Sentry. code_file : null | string Path and name of the image file (required). The absolute path to the dynamic library or executable. This helps to locate the file if it is missing on Sentry. pe : The code file should be provided to allow server-side stack walking of binary crash reports, such as Minidumps. code_id (optional): null | string Optional identifier of the code file. elf : If the program was compiled with a relatively recent compiler, this should be the hex representation of the NT_GNU_BUILD_ID program header (type PT_NOTE ), or the value of the .note.gnu.build-id note section (type SHT_NOTE ). Otherwise, leave this value empty. Certain symbol servers use the code identifier to locate debug information for ELF images, in which case this field should be included if possible. pe : Identifier of the executable or DLL. It contains the values of the time_date_stamp from the COFF header and size_of_image from the optional header formatted together into a hex string using %08x%X (note that the second value is not padded): text time_date_stamp: 0x5ab38077 size_of_image: 0x9000 code_id: 5ab380779000 The code identifier should be provided to allow server-side stack walking of binary crash reports, such as Minidumps. macho : Identifier of the dynamic library or executable. It is the value of the LC_UUID load command in the Mach header, formatted as UUID. Can be empty for Mach images, as it is equivalent to the debug identifier. debug_file (optional): null | string Path and name of the debug companion file. elf : Name or absolute path to the file containing stripped debug information for this image. This value might be required to retrieve debug files from certain symbol servers. pe : Name of the PDB file containing debug information for this image. This value is often required to retrieve debug files from specific symbol servers. macho : Name or absolute path to the dSYM file containing debug information for this image. This value might be required to retrieve debug files from certain symbol servers. debug_id : null | string Unique debug identifier of the image. elf : Debug identifier of the dynamic library or executable. If a code identifier is available, the debug identifier is the little-endian UUID representation of the first 16-bytes of that identifier. Spaces are inserted for readability, note the byte order of the first fields: text code id: f1c3bcc0 2798 65fe 3058 404b2831d9e6 4135386c debug id: c0bcc3f1-9827-fe65-3058-404b2831d9e6 If no code id is available, the debug id should be computed by XORing the first 4096 bytes of the .text section in 16-byte chunks, and representing it as a little-endian UUID (again swapping the byte order). pe : signature and age of the PDB file. Both values can be read from the CodeView PDB70 debug information header in the PE. The value should be represented as little-endian UUID, with the age appended at the end. Note that the byte order of the UUID fields must be swapped (spaces inserted for readability): text signature: f1c3bcc0 2798 65fe 3058 404b2831d9e6 age: 1 debug_id: c0bcc3f1-9827-fe65-3058-404b2831d9e6-1 macho : Identifier of the dynamic library or executable. It is the value of the LC_UUID load command in the Mach header, formatted as UUID. image_addr : null | string Starting memory address of the image (required). Memory address, at which the image is mounted in the virtual address space of the process. Should be a string in hex representation prefixed with \"0x\" . image_size : number | null Size of the image in bytes (required). The size of the image in virtual memory. If missing, Sentry will assume that the image spans up to the next image, which might lead to invalid stack traces. image_vmaddr (optional): null | string Loading address in virtual memory. Preferred load address of the image in virtual memory, as declared in the headers of the image. When loading an image, the operating system may still choose to place it at a different address. Symbols and addresses in the native image are always relative to the start of the image and do not consider the preferred load address. It is merely a hint to the loader. elf / macho : If this value is non-zero, all symbols and addresses declared in the native image start at this address, rather than 0. By contrast, Sentry deals with addresses relative to the start of the image. For example, with image_vmaddr: 0x40000 , a symbol located at 0x401000 has a relative address of 0x1000 . Relative addresses used in Apple Crash Reports and addr2line are usually in the preferred address space, and not relative address space.","title":"NativeDebugImage"},{"location":"event-schema/#proguarddebugimage","text":"Proguard mapping file. Proguard images refer to mapping.txt files generated when Proguard obfuscates function names. The Java SDK integrations assign this file a unique identifier, which has to be included in the list of images. Properties: uuid : null | string UUID computed from the file contents, assigned by the Java SDK.","title":"ProguardDebugImage"},{"location":"event-schema/#systemsdkinfo","text":"Holds information about the system SDK. This is relevant for iOS and other platforms that have a system SDK. Not to be confused with the client SDK. Properties: sdk_name (optional): null | string The internal name of the SDK. version_major (optional): number | null The major version of the SDK as integer or 0. version_minor (optional): number | null The minor version of the SDK as integer or 0. version_patchlevel (optional): number | null The patch version of the SDK as integer or 0.","title":"SystemSDKInfo"},{"location":"event-schema/#eventprocessingerror","text":"An event processing error. Properties: name (optional): null | string Affected key or deep path. type : null | string The error kind. value (optional): any The original value causing this error.","title":"EventProcessingError"},{"location":"event-schema/#exception","text":"Properties: values : Array<null | ValueObject >","title":"Exception"},{"location":"event-schema/#valueobject","text":"A single exception. Multiple values inside of an event represent chained exceptions and should be sorted oldest to newest. For example, consider this Python code snippet: python try: raise Exception(\"random boring invariant was not met!\") except Exception as e: raise ValueError(\"something went wrong, help!\") from e Exception would be described first in the values list, followed by a description of ValueError : json { \"exception\": { \"values\": [ {\"type\": \"Exception\": \"value\": \"random boring invariant was not met!\"}, {\"type\": \"ValueError\", \"value\": \"something went wrong, help!\"}, ] } } Properties: mechanism (optional): null | Mechanism Mechanism by which this exception was generated and handled. module (optional): null | string The optional module, or package which the exception type lives in. stacktrace (optional): null | Stacktrace Stack trace containing frames of this exception. thread_id (optional): null | (number | string) An optional value which refers to a thread . type (optional): null | string Exception type, e.g. ValueError . At least one of type or value is required, otherwise the exception is discarded. value (optional): null | string Human readable display value. At least one of type or value is required, otherwise the exception is discarded.","title":"ValueObject"},{"location":"event-schema/#mechanism","text":"The mechanism by which an exception was generated and handled. The exception mechanism is an optional field residing in the exception . It carries additional information about the way the exception was created on the target system. This includes general exception values obtained from the operating system or runtime APIs, as well as mechanism-specific values. Properties: data (optional): { [key: string]: any } | null Additional attributes depending on the mechanism type. description (optional): null | string Optional human-readable description of the error mechanism. May include a possible hint on how to solve this error. handled (optional): boolean | null Flag indicating whether this exception was handled. This is a best-effort guess at whether the exception was handled by user code or not. For example: Exceptions leading to a 500 Internal Server Error or to a hard process crash are handled=false , as the SDK typically has an integration that automatically captures the error. Exceptions captured using capture_exception (called from user code) are handled=true as the user explicitly captured the exception (and therefore kind of handled it) help_link (optional): null | string Link to online resources describing this error. meta (optional): null | MechanismMeta Operating system or runtime meta information. synthetic (optional): boolean | null If this is set then the exception is not a real exception but some form of synthetic error for instance from a signal handler, a hard segfault or similar where type and value are not useful for grouping or display purposes. type : null | string Mechanism type (required). Required unique identifier of this mechanism determining rendering and processing of the mechanism data. In the Python SDK this is merely the name of the framework integration that produced the exception, while for native it is e.g. \"minidump\" or \"applecrashreport\" .","title":"Mechanism"},{"location":"event-schema/#mechanismmeta","text":"Operating system or runtime meta information to an exception mechanism. The mechanism metadata usually carries error codes reported by the runtime or operating system, along with a platform-dependent interpretation of these codes. SDKs can safely omit code names and descriptions for well-known error codes, as it will be filled out by Sentry. For proprietary or vendor-specific error codes, adding these values will give additional information to the user. Properties: errno (optional): null | CError Optional ISO C standard error code. mach_exception (optional): null | MachException A Mach Exception on Apple systems comprising a code triple and optional descriptions. signal (optional): null | POSIXSignal Information on the POSIX signal.","title":"MechanismMeta"},{"location":"event-schema/#cerror","text":"POSIX signal with optional extended data. Error codes set by Linux system calls and some library functions as specified in ISO C99, POSIX.1-2001, and POSIX.1-2008. See errno(3) for more information. Properties: name (optional): null | string Optional name of the errno constant. number (optional): number | null The error code as specified by ISO C99, POSIX.1-2001 or POSIX.1-2008.","title":"CError"},{"location":"event-schema/#machexception","text":"Mach exception information. Properties: code (optional): number | null The mach exception code. exception (optional): number | null The mach exception type. name (optional): null | string Optional name of the mach exception. subcode (optional): number | null The mach exception subcode.","title":"MachException"},{"location":"event-schema/#posixsignal","text":"POSIX signal with optional extended data. On Apple systems, signals also carry a code in addition to the signal number describing the signal in more detail. On Linux, this code does not exist. Properties: code (optional): number | null An optional signal code present on Apple systems. code_name (optional): null | string Optional name of the errno constant. name (optional): null | string Optional name of the errno constant. number (optional): number | null The POSIX signal number.","title":"POSIXSignal"},{"location":"event-schema/#stacktrace","text":"A stack trace of a single thread. A stack trace contains a list of frames, each with various bits (most optional) describing the context of that frame. Frames should be sorted from oldest to newest. For the given example program written in Python: ```python def foo(): my_var = 'foo' raise ValueError() def main(): foo() ``` A minimalistic stack trace for the above program in the correct order: json { \"frames\": [ {\"function\": \"main\"}, {\"function\": \"foo\"} ] } The top frame fully symbolicated with five lines of source context: json { \"frames\": [{ \"in_app\": true, \"function\": \"myfunction\", \"abs_path\": \"/real/file/name.py\", \"filename\": \"file/name.py\", \"lineno\": 3, \"vars\": { \"my_var\": \"'value'\" }, \"pre_context\": [ \"def foo():\", \" my_var = 'foo'\", ], \"context_line\": \" raise ValueError()\", \"post_context\": [ \"\", \"def main():\" ], }] } A minimal native stack trace with register values. Note that the package event attribute must be \"native\" for these frames to be symbolicated. json { \"frames\": [ {\"instruction_addr\": \"0x7fff5bf3456c\"}, {\"instruction_addr\": \"0x7fff5bf346c0\"}, ], \"registers\": { \"rip\": \"0x00007ff6eef54be2\", \"rsp\": \"0x0000003b710cd9e0\" } } Properties: frames : Array<null | Frame > | null Required. A non-empty list of stack frames. The list is ordered from caller to callee, or oldest to youngest. The last frame is the one creating the exception. lang (optional): null | string The language of the stacktrace. registers (optional): { [key: string]: null | string } | null Register values of the thread (top frame). A map of register names and their values. The values should contain the actual register values of the thread, thus mapping to the last frame in the list.","title":"Stacktrace"},{"location":"event-schema/#frame","text":"Holds information about a single stacktrace frame. Each object should contain at least a filename , function or instruction_addr attribute. All values are optional, but recommended. Properties: abs_path (optional): null | string Absolute path to the source file. colno (optional): number | null Column number within the source file, starting at 1. context_line (optional): null | string Source code of the current line ( lineno ). filename (optional): null | string The source file name (basename only). function (optional): null | string Name of the frame's function. This might include the name of a class. This function name may be shortened or demangled. If not, Sentry will demangle and shorten it for some platforms. The original function name will be stored in raw_function . image_addr (optional): null | string (C/C++/Native) Start address of the containing code module (image). in_app (optional): boolean | null Override whether this frame should be considered part of application code, or part of libraries/frameworks/dependencies. Setting this attribute to false causes the frame to be hidden/collapsed by default and mostly ignored during issue grouping. instruction_addr (optional): null | string (C/C++/Native) Absolute address of the frame's CPU instruction. lineno (optional): number | null Line number within the source file, starting at 1. module (optional): null | string Name of the module the frame is contained in. Note that this might also include a class name if that is something the language natively considers to be part of the stack (for instance in Java). package (optional): null | string Name of the package that contains the frame. For instance this can be a dylib for native languages, the name of the jar or .NET assembly. platform (optional): null | string Which platform this frame is from. This can override the platform for a single frame. Otherwise, the platform of the event is assumed. This can be used for multi-platform stack traces, such as in React Native. post_context (optional): Array<null | string> | null Source code of the lines after lineno . pre_context (optional): Array<null | string> | null Source code leading up to lineno . raw_function (optional): null | string A raw (but potentially truncated) function value. The original function name, if the function name is shortened or demangled. Sentry shows the raw function when clicking on the shortened one in the UI. If this has the same value as function it's best to be omitted. This exists because on many platforms the function itself contains additional information like overload specifies or a lot of generics which can make it exceed the maximum limit we provide for the field. In those cases then we cannot reliably trim down the function any more at a later point because the more valuable information has been removed. The logic to be applied is that an intelligently trimmed function name should be stored in function and the value before trimming is stored in this field instead. However also this field will be capped at 256 characters at the moment which often means that not the entire original value can be stored. symbol (optional): null | string Potentially mangled name of the symbol as it appears in an executable. This is different from a function name by generally being the mangled name that appears natively in the binary. This is relevant for languages like Swift, C++ or Rust. symbol_addr (optional): null | string (C/C++/Native) Start address of the frame's function. vars (optional): { [key: string]: any } | null Mapping of local variables and expression names that were available in this frame.","title":"Frame"},{"location":"event-schema/#logentry","text":"A log entry message. A log message is similar to the message attribute on the event itself but can additionally hold optional parameters. json { \"message\": { \"message\": \"My raw message with interpreted strings like %s\", \"params\": [\"this\"] } } json { \"message\": { \"message\": \"My raw message with interpreted strings like {foo}\", \"params\": {\"foo\": \"this\"} } } Properties: formatted (optional): null | string The formatted message. If message and params are given, Sentry will attempt to backfill formatted if empty. It must not exceed 8192 characters. Longer messages will be truncated. message (optional): null | string The log message with parameter placeholders. This attribute is primarily used for grouping related events together into issues. Therefore this really should just be a string template, i.e. Sending %d requests instead of Sending 9999 requests . The latter is much better at home in formatted . It must not exceed 8192 characters. Longer messages will be truncated. params (optional): any Parameters to be interpolated into the log message. This can be an array of positional parameters as well as a mapping of named arguments to their values.","title":"LogEntry"},{"location":"event-schema/#request","text":"Http request information. The Request interface contains information on a HTTP request related to the event. In client SDKs, this can be an outgoing request, or the request that rendered the current web page. On server SDKs, this could be the incoming web request that is being handled. The data variable should only contain the request body (not the query string). It can either be a dictionary (for standard HTTP requests) or a raw request body.","title":"Request"},{"location":"event-schema/#ordered-maps","text":"In the Request interface, several attributes can either be declared as string, object, or list of tuples. Sentry attempts to parse structured information from the string representation in such cases. Sometimes, keys can be declared multiple times, or the order of elements matters. In such cases, use the tuple representation over a plain object. Example of request headers as object: json { \"content-type\": \"application/json\", \"accept\": \"application/json, application/xml\" } Example of the same headers as list of tuples: json [ [\"content-type\", \"application/json\"], [\"accept\", \"application/json\"], [\"accept\", \"application/xml\"] ] Example of a fully populated request object: json { \"request\": { \"method\": \"POST\", \"url\": \"http://absolute.uri/foo\", \"query_string\": \"query=foobar&page=2\", \"data\": { \"foo\": \"bar\" }, \"cookies\": \"PHPSESSID=298zf09hf012fh2; csrftoken=u32t4o3tb3gg43; _gat=1;\", \"headers\": { \"content-type\": \"text/html\" }, \"env\": { \"REMOTE_ADDR\": \"192.168.0.1\" } } } Properties: cookies (optional): null | (Array<Array<(null | string)> | null> | { [key: string]: null | string }) The cookie values. Can be given unparsed as string, as dictionary, or as a list of tuples. data (optional): any Request data in any format that makes sense. SDKs should discard large and binary bodies by default. Can be given as string or structural data of any format. env (optional): { [key: string]: any } | null Server environment data, such as CGI/WSGI. A dictionary containing environment information passed from the server. This is where information such as CGI/WSGI/Rack keys go that are not HTTP headers. Sentry will explicitly look for REMOTE_ADDR to extract an IP address. fragment (optional): null | string The fragment of the request URL. headers (optional): null | (Array<Array<(null | string)> | null> | { [key: string]: null | string }) A dictionary of submitted headers. If a header appears multiple times it, needs to be merged according to the HTTP standard for header merging. Header names are treated case-insensitively by Sentry. inferred_content_type (optional): null | string The inferred content type of the request payload. method (optional): null | string HTTP request method. query_string (optional): null | (Array<Array<(null | string)> | null> | { [key: string]: null | string }) The query string component of the URL. Can be given as unparsed string, dictionary, or list of tuples. If the query string is not declared and part of the url , Sentry moves it to the query string. url (optional): null | string The URL of the request if available. The query string can be declared either as part of the url , or separately in query_string .","title":"Ordered Maps"},{"location":"event-schema/#clientsdkinfo","text":"The SDK Interface describes the Sentry SDK and its configuration used to capture and transmit an event. Properties: integrations (optional): Array<null | string> | null List of integrations that are enabled in the SDK. Optional. The list should have all enabled integrations, including default integrations. Default integrations are included because different SDK releases may contain different default integrations. name : null | string Unique SDK name. Required. The name of the SDK. The format is entity.ecosystem[.flavor] where entity identifies the developer of the SDK, ecosystem refers to the programming language or platform where the SDK is to be used and the optional flavor is used to identify standalone SDKs that are part of a major ecosystem. Official Sentry SDKs use the entity sentry , as in sentry.python or sentry.javascript.react-native . Please use a different entity for your own SDKs. packages (optional): Array<null | ClientSDKPackage > | null List of installed and loaded SDK packages. Optional. A list of packages that were installed as part of this SDK or the activated integrations. Each package consists of a name in the format source:identifier and version . If the source is a Git repository, the source should be git , the identifier should be a checkout link and the version should be a Git reference (branch, tag or SHA). version : null | string The version of the SDK. Required. It should have the Semantic Versioning format MAJOR.MINOR.PATCH , without any prefix (no v or anything else in front of the major version number). Examples: 0.1.0 , 1.0.0 , 4.3.12","title":"ClientSDKInfo"},{"location":"event-schema/#clientsdkpackage","text":"An installed and loaded package as part of the Sentry SDK. Properties: name (optional): null | string Name of the package. version (optional): null | string Version of the package.","title":"ClientSDKPackage"},{"location":"event-schema/#span","text":"Properties: description (optional): null | string Human readable description of a span (e.g. method URL). op (optional): null | string Span type (see OperationType docs). parent_span_id (optional): null | string The ID of the span enclosing this span. span_id : null | string The Span id. start_timestamp : null | (number | string) Timestamp when the span started. status (optional): SpanStatus | null The status of a span timestamp : null | (number | string) Timestamp when the span was ended. trace_id : null | string The ID of the trace the span belongs to.","title":"Span"},{"location":"event-schema/#threads","text":"Properties: values : Array<null | Thread >","title":"Threads"},{"location":"event-schema/#thread","text":"A process thread of an event. The Threads Interface specifies threads that were running at the time an event happened. These threads can also contain stack traces. An event may contain one or more threads in an attribute named threads . The following example illustrates the threads part of the event payload and omits other attributes for simplicity. json { \"threads\": { \"values\": [ { \"id\": \"0\", \"name\": \"main\", \"crashed\": true, \"stacktrace\": {} } ] } } Properties: crashed (optional): boolean | null A flag indicating whether the thread crashed. Defaults to false . current (optional): boolean | null A flag indicating whether the thread was in the foreground. Defaults to false . id (optional): null | (number | string) The ID of the thread. Typically a number or numeric string. Needs to be unique among the threads. An exception can set the thread_id attribute to cross-reference this thread. name (optional): null | string Display name of this thread. stacktrace (optional): null | Stacktrace Stack trace containing frames of this exception. The thread that crashed with an exception should not have a stack trace, but instead, the thread_id attribute should be set on the exception and Sentry will connect the two.","title":"Thread"},{"location":"event-schema/#eventtype","text":"The type of an event. Variants: \"csp\" \"default\" \"error\" \"expectct\" \"expectstaple\" \"hpkp\" \"transaction\"","title":"EventType"},{"location":"event-schema/#user","text":"Information about the user who triggered an event. json { \"user\": { \"id\": \"unique_id\", \"username\": \"my_user\", \"email\": \"foo@example.com\", \"ip_address\": \"127.0.0.1\", \"subscription\": \"basic\" } } Properties: data (optional): { [key: string]: any } | null Additional arbitrary fields, as stored in the database (and sometimes as sent by clients). All data from self.other should end up here after store normalization. email (optional): null | string Email address of the user. geo (optional): null | Geo Approximate geographical location of the end user or device. id (optional): null | string Unique identifier of the user. ip_address (optional): null | string Remote IP address of the user. Defaults to \"\". name (optional): null | string Human readable name of the user. username (optional): null | string Username of the user.","title":"User"},{"location":"event-schema/#geo","text":"Geographical location of the end user or device. Properties: city (optional): null | string Human readable city name. country_code (optional): null | string Two-letter country code (ISO 3166-1 alpha-2). region (optional): null | string Human readable region name or code.","title":"Geo"},{"location":"pii-config/","text":"PII Configuration The following document explores the syntax and semantics of the new datascrubbing (\"PII\") configuration consumed by Relay . A Basic Example Say you have an exception message which, unfortunately, contains IP addresses which are not supposed to be there. You'd write: { \"applications\" : { \"$string\" : [ \"@ip:replace\" ] } } It reads as \"replace all IP addresses in all strings\", or \"apply @ip:replace to all $string fields\". @ip:replace is called a rule, and $string is a selector . Built-in Rules The following rules exist by default: @ip:replace and @ip:hash for replacing IP addresses. @imei:replace and @imei:hash for replacing IMEIs @mac:replace , @mac:mask and @mac:hash for matching MAC addresses @email:mask , @email:replace and @email:hash for matching email addresses @creditcard:mask , @creditcard:replace and @creditcard:hash for matching creditcard numbers @userpath:replace and @userpath:hash for matching local paths (e.g. C:/Users/foo/ ) @password:remove for removing passwords. In this case we're pattern matching against the field's key, whether it contains password , credentials or similar strings. @anything:remove , @anything:replace and @anything:hash for removing, replacing or hashing any value. It is essentially equivalent to a wildcard-regex, but it will also match much more than strings. Writing Your Own Rules Rules generally consist of two parts: Rule types describe what to match. See PII Rule Types for an exhaustive list. Rule redaction methods describe what to do with the match. See PII Redaction Methods for a list. Each page comes with examples. Try those examples out by pasting them into the \"PII config\" column of Piinguin and clicking on fields to get suggestions. Interactive Editing The easiest way to go about this is if you already have a raw JSON payload from some SDK. Go to our PII config editor Piinguin , and: Paste in a raw event Click on data you want eliminated Paste in other payloads and see if they look fine, go to step 2 if necessary. After iterating on the config, paste it back into the project config located at .relay/projects/<PROJECT_ID>.json For example: { \"publicKeys\" : [ { \"publicKey\" : \"___PUBLIC_KEY___\" , \"isEnabled\" : true } ], \"config\" : { \"allowedDomains\" : [ \"*\" ], \"piiConfig\" : { \"rules\" : { \"device_id\" : { \"type\" : \"pattern\" , \"pattern\" : \"d/[a-f0-9]{12}\" , \"redaction\" : { \"method\" : \"hash\" } } }, \"applications\" : { \"freeform\" : [ \"device_id\" ] } } } }","title":"PII Configuration"},{"location":"pii-config/#pii-configuration","text":"The following document explores the syntax and semantics of the new datascrubbing (\"PII\") configuration consumed by Relay .","title":"PII Configuration"},{"location":"pii-config/#a-basic-example","text":"Say you have an exception message which, unfortunately, contains IP addresses which are not supposed to be there. You'd write: { \"applications\" : { \"$string\" : [ \"@ip:replace\" ] } } It reads as \"replace all IP addresses in all strings\", or \"apply @ip:replace to all $string fields\". @ip:replace is called a rule, and $string is a selector .","title":"A Basic Example"},{"location":"pii-config/#built-in-rules","text":"The following rules exist by default: @ip:replace and @ip:hash for replacing IP addresses. @imei:replace and @imei:hash for replacing IMEIs @mac:replace , @mac:mask and @mac:hash for matching MAC addresses @email:mask , @email:replace and @email:hash for matching email addresses @creditcard:mask , @creditcard:replace and @creditcard:hash for matching creditcard numbers @userpath:replace and @userpath:hash for matching local paths (e.g. C:/Users/foo/ ) @password:remove for removing passwords. In this case we're pattern matching against the field's key, whether it contains password , credentials or similar strings. @anything:remove , @anything:replace and @anything:hash for removing, replacing or hashing any value. It is essentially equivalent to a wildcard-regex, but it will also match much more than strings.","title":"Built-in Rules"},{"location":"pii-config/#writing-your-own-rules","text":"Rules generally consist of two parts: Rule types describe what to match. See PII Rule Types for an exhaustive list. Rule redaction methods describe what to do with the match. See PII Redaction Methods for a list. Each page comes with examples. Try those examples out by pasting them into the \"PII config\" column of Piinguin and clicking on fields to get suggestions.","title":"Writing Your Own Rules"},{"location":"pii-config/#interactive-editing","text":"The easiest way to go about this is if you already have a raw JSON payload from some SDK. Go to our PII config editor Piinguin , and: Paste in a raw event Click on data you want eliminated Paste in other payloads and see if they look fine, go to step 2 if necessary. After iterating on the config, paste it back into the project config located at .relay/projects/<PROJECT_ID>.json For example: { \"publicKeys\" : [ { \"publicKey\" : \"___PUBLIC_KEY___\" , \"isEnabled\" : true } ], \"config\" : { \"allowedDomains\" : [ \"*\" ], \"piiConfig\" : { \"rules\" : { \"device_id\" : { \"type\" : \"pattern\" , \"pattern\" : \"d/[a-f0-9]{12}\" , \"redaction\" : { \"method\" : \"hash\" } } }, \"applications\" : { \"freeform\" : [ \"device_id\" ] } } } }","title":"Interactive Editing"},{"location":"pii-config/methods/","text":"PII Redaction Methods remove Remove the entire field. Relay may choose to either set it to null or to remove it entirely. { \"rules\" : { \"remove_ip\" : { \"type\" : \"ip\" , \"redaction\" : { \"method\" : \"remove\" } } }, \"applications\" : { \"$string\" : [ \"remove_ip\" ] } } replace Replace the key with a static string. { \"rules\" : { \"replace_ip\" : { \"type\" : \"ip\" , \"redaction\" : { \"method\" : \"replace\" , \"text\" : [ censored ] \" } } }, \" applications \": { \" $string \": [\" replace_ip\"] } } mask Replace every character of the matched string with a \"masking\" char. Compared to replace this preserves the length of the original string. { \"rules\" : { \"mask_ip\" : { \"type\" : \"ip\" , \"redaction\" : { \"method\" : \"mask\" , \"mask_char\" : \"0\" , // The character used for masking. Optional, default \"*\" \"chars_to_ignore\" : \".\" , // Which characters to ignore. Optional, default empty \"range\" : [ 0 , - 1 ] // Which range of the string to replace. Optional, defaults to full range. Negative indices count from the matches' end. } } }, \"applications\" : { \"$string\" : [ \"mask_ip\" ] } } hash Replace the string with a hashed version of itself. Equal strings will produce the same hash, so if you, for example, decide to hash the user ID instead of replacing or removing it, you will still have an accurate count of users affected. { \"rules\" : { \"hash_ip\" : { \"type\" : \"ip\" , \"redaction\" : { \"method\" : \"hash\" , \"algorithm\" : \"HMAC-SHA1\" , // One of \"HMAC-SHA1\", \"HMAC-SHA256\", \"HMAC-SHA512\" \"key\" : \"myOverriddenKey\" // A key to salt the hash with. Defaults to the default key set in \"vars\" } } }, \"vars\" : { \"hashKey\" : \"myDefaultKey\" // The default key to use } \"applications\" : { \"$string\" : [ \"mask_ip\" ] } }","title":"PII Redaction Methods"},{"location":"pii-config/methods/#pii-redaction-methods","text":"","title":"PII Redaction Methods"},{"location":"pii-config/methods/#remove","text":"Remove the entire field. Relay may choose to either set it to null or to remove it entirely. { \"rules\" : { \"remove_ip\" : { \"type\" : \"ip\" , \"redaction\" : { \"method\" : \"remove\" } } }, \"applications\" : { \"$string\" : [ \"remove_ip\" ] } }","title":"remove"},{"location":"pii-config/methods/#replace","text":"Replace the key with a static string. { \"rules\" : { \"replace_ip\" : { \"type\" : \"ip\" , \"redaction\" : { \"method\" : \"replace\" , \"text\" : [ censored ] \" } } }, \" applications \": { \" $string \": [\" replace_ip\"] } }","title":"replace"},{"location":"pii-config/methods/#mask","text":"Replace every character of the matched string with a \"masking\" char. Compared to replace this preserves the length of the original string. { \"rules\" : { \"mask_ip\" : { \"type\" : \"ip\" , \"redaction\" : { \"method\" : \"mask\" , \"mask_char\" : \"0\" , // The character used for masking. Optional, default \"*\" \"chars_to_ignore\" : \".\" , // Which characters to ignore. Optional, default empty \"range\" : [ 0 , - 1 ] // Which range of the string to replace. Optional, defaults to full range. Negative indices count from the matches' end. } } }, \"applications\" : { \"$string\" : [ \"mask_ip\" ] } }","title":"mask"},{"location":"pii-config/methods/#hash","text":"Replace the string with a hashed version of itself. Equal strings will produce the same hash, so if you, for example, decide to hash the user ID instead of replacing or removing it, you will still have an accurate count of users affected. { \"rules\" : { \"hash_ip\" : { \"type\" : \"ip\" , \"redaction\" : { \"method\" : \"hash\" , \"algorithm\" : \"HMAC-SHA1\" , // One of \"HMAC-SHA1\", \"HMAC-SHA256\", \"HMAC-SHA512\" \"key\" : \"myOverriddenKey\" // A key to salt the hash with. Defaults to the default key set in \"vars\" } } }, \"vars\" : { \"hashKey\" : \"myDefaultKey\" // The default key to use } \"applications\" : { \"$string\" : [ \"mask_ip\" ] } }","title":"hash"},{"location":"pii-config/selectors/","text":"PII Selectors Selectors allow you to restrict rules to certain parts of the event. This is useful to unconditionally remove certain data by variable/field name from the event, but can also be used to conservatively test rules on real data. Data scrubbing always works on the raw event payload. Keep in mind that some fields in the UI may be called differently in the JSON schema. When looking at an event there should always be a link called \"JSON\" present that allows you to see what the data scrubber sees. For example, what is called \"Additional Data\" in the UI is called extra in the event payload. To remove a specific key called foo , you would write: [ Remove ] [ Anything ] from [ extra.foo ] Another example. Sentry knows about two kinds of error messages: The exception message, and the top-level log message. Here is an example of how such an event payload as sent by the SDK (and downloadable from the UI) would look like: { \"logentry\" : { \"formatted\" : \"Failed to roll out the dinglebop\" }, \"exceptions\" : { \"values\" : [ { \"type\" : \"ZeroDivisionError\" , \"value\" : \"integer division or modulo by zero\" , } ] } } Since the \"error message\" is taken from the exception 's value , and the \"message\" is taken from logentry , we would have to write the following to remove both from the event: [Remove] [Anything] from [exception.value] [Remove] [Anything] from [logentry.formatted] Boolean Logic You can combine selectors using boolean logic. Prefix with ! to invert the selector. foo matches the JSON key foo , while !foo matches everything but foo . Build the conjunction (AND) using && , such as: foo && !extra.foo to match the key foo except when inside of extra . Build the disjunction (OR) using || , such as: foo || bar to match foo or bar . Wildcards ** matches all subpaths, so that foo.** matches all JSON keys within foo . * matches a single path item, so that foo.* matches all JSON keys one level below foo . Value Types Select subsections by JSON-type using the following: $string matches any string value $number matches any integer or float value $datetime matches any field in the event that represents a timestamp $array matches any JSON array value $object matches any JSON object Select known parts of the schema using the following: $exception matches a single exception instance in {\"exception\": {\"values\": [...]}} $stacktrace matches a stack trace instance $frame matches a frame $request matches the HTTP request context of an event $user matches the user context of an event $logentry (also applies to the message attribute) $thread matches a single thread instance in {\"threads\": {\"values\": [...]}} $breadcrumb matches a single breadcrumb in {\"breadcrumbs\": [...]} $span matches a trace span $sdk matches the SDK context in {\"sdk\": ...} Examples Delete event.user : [ Remove ] [ Anything ] from [ $user ] Delete all frame-local variables: [ Remove ] [ Anything ] from [ $frame.vars ] Escaping Specal Characters If the object key you want to match contains whitespace or special characters, you can use quotes to escape it: [ Remove ] [ Anything ] from [ extra.'my special value' ] This matches the key my special value in Additional Data . To escape ' (single quote) within the quotes, replace it with '' (two quotes): [ Remove ] [ Anything ] from [ extra.'my special '' value' ] This matches the key my special ' value in Additional Data .","title":"PII Selectors"},{"location":"pii-config/selectors/#pii-selectors","text":"Selectors allow you to restrict rules to certain parts of the event. This is useful to unconditionally remove certain data by variable/field name from the event, but can also be used to conservatively test rules on real data. Data scrubbing always works on the raw event payload. Keep in mind that some fields in the UI may be called differently in the JSON schema. When looking at an event there should always be a link called \"JSON\" present that allows you to see what the data scrubber sees. For example, what is called \"Additional Data\" in the UI is called extra in the event payload. To remove a specific key called foo , you would write: [ Remove ] [ Anything ] from [ extra.foo ] Another example. Sentry knows about two kinds of error messages: The exception message, and the top-level log message. Here is an example of how such an event payload as sent by the SDK (and downloadable from the UI) would look like: { \"logentry\" : { \"formatted\" : \"Failed to roll out the dinglebop\" }, \"exceptions\" : { \"values\" : [ { \"type\" : \"ZeroDivisionError\" , \"value\" : \"integer division or modulo by zero\" , } ] } } Since the \"error message\" is taken from the exception 's value , and the \"message\" is taken from logentry , we would have to write the following to remove both from the event: [Remove] [Anything] from [exception.value] [Remove] [Anything] from [logentry.formatted]","title":"PII Selectors"},{"location":"pii-config/selectors/#boolean-logic","text":"You can combine selectors using boolean logic. Prefix with ! to invert the selector. foo matches the JSON key foo , while !foo matches everything but foo . Build the conjunction (AND) using && , such as: foo && !extra.foo to match the key foo except when inside of extra . Build the disjunction (OR) using || , such as: foo || bar to match foo or bar .","title":"Boolean Logic"},{"location":"pii-config/selectors/#wildcards","text":"** matches all subpaths, so that foo.** matches all JSON keys within foo . * matches a single path item, so that foo.* matches all JSON keys one level below foo .","title":"Wildcards"},{"location":"pii-config/selectors/#value-types","text":"Select subsections by JSON-type using the following: $string matches any string value $number matches any integer or float value $datetime matches any field in the event that represents a timestamp $array matches any JSON array value $object matches any JSON object Select known parts of the schema using the following: $exception matches a single exception instance in {\"exception\": {\"values\": [...]}} $stacktrace matches a stack trace instance $frame matches a frame $request matches the HTTP request context of an event $user matches the user context of an event $logentry (also applies to the message attribute) $thread matches a single thread instance in {\"threads\": {\"values\": [...]}} $breadcrumb matches a single breadcrumb in {\"breadcrumbs\": [...]} $span matches a trace span $sdk matches the SDK context in {\"sdk\": ...}","title":"Value Types"},{"location":"pii-config/selectors/#examples","text":"Delete event.user : [ Remove ] [ Anything ] from [ $user ] Delete all frame-local variables: [ Remove ] [ Anything ] from [ $frame.vars ]","title":"Examples"},{"location":"pii-config/selectors/#escaping-specal-characters","text":"If the object key you want to match contains whitespace or special characters, you can use quotes to escape it: [ Remove ] [ Anything ] from [ extra.'my special value' ] This matches the key my special value in Additional Data . To escape ' (single quote) within the quotes, replace it with '' (two quotes): [ Remove ] [ Anything ] from [ extra.'my special '' value' ] This matches the key my special ' value in Additional Data .","title":"Escaping Specal Characters"},{"location":"pii-config/types/","text":"PII Rule Types pattern Custom Perl-style regex (PCRE). { \"rules\" : { \"hash_device_id\" : { \"type\" : \"pattern\" , \"pattern\" : \"d/[a-f0-9]{12}\" , \"redaction\" : { \"method\" : \"hash\" } } }, \"applications\" : { \"$string\" : [ \"hash_device_id\" ] } } imei Matches an IMEI or IMEISV. { \"rules\" : { \"hash_imei\" : { \"type\" : \"imei\" , \"redaction\" : { \"method\" : \"hash\" } } }, \"applications\" : { \"$string\" : [ \"hash_imei\" ] } } mac Matches a MAC address. { \"rules\" : { \"hash_mac\" : { \"type\" : \"mac\" , \"redaction\" : { \"method\" : \"hash\" } } }, \"applications\" : { \"$string\" : [ \"hash_mac\" ] } } ip Matches any IP address. { \"rules\" : { \"hash_ip\" : { \"type\" : \"ip\" , \"redaction\" : { \"method\" : \"hash\" } } }, \"applications\" : { \"$string\" : [ \"hash_ip\" ] } } creditcard Matches a creditcard number. { \"rules\" : { \"hash_cc\" : { \"type\" : \"creditcard\" , \"redaction\" : { \"method\" : \"hash\" } } }, \"applications\" : { \"$string\" : [ \"hash_cc\" ] } } userpath Matches a local path (e.g. C:/Users/foo/ ). { \"rules\" : { \"hash_userpath\" : { \"type\" : \"userpath\" , \"redaction\" : { \"method\" : \"hash\" } } }, \"applications\" : { \"$string\" : [ \"hash_userpath\" ] } } anything Matches any value. This is basically equivalent to a wildcard regex. For example, to remove all strings: { \"rules\" : { \"remove_everything\" : { \"type\" : \"anything\" , \"redaction\" : { \"method\" : \"remove\" } } }, \"applications\" : { \"$string\" : [ \"remove_everything\" ] } } multiple Combine multiple rules into one. This is a disjunction (OR): The field in question has to match only one of the rules to match the combined rule, not all of them. { \"rules\" : { \"remove_ips_and_macs\" : { \"type\" : \"multiple\" , \"rules\" : [ \"@ip\" , \"@mac\" ], \"hide_rule\" : false , // Hide the inner rules when showing which rules have been applied. Defaults to false. \"redaction\" : { \"method\" : \"remove\" } } }, \"applications\" : { \"$string\" : [ \"remove_ips_and_macs\" ] } } alias Alias one rule to the other. This is the same as multiple except that you can only wrap one rule. { \"rules\" : { \"remove_ips\" : { \"type\" : \"multiple\" , \"rule\" : \"@ip\" , \"hide_rule\" : false , // Hide the inner rule when showing which rules have been applied. Defaults to false. \"redaction\" : { \"method\" : \"remove\" } } }, \"applications\" : { \"$string\" : [ \"remove_ips\" ] } }","title":"PII Rule Types"},{"location":"pii-config/types/#pii-rule-types","text":"","title":"PII Rule Types"},{"location":"pii-config/types/#pattern","text":"Custom Perl-style regex (PCRE). { \"rules\" : { \"hash_device_id\" : { \"type\" : \"pattern\" , \"pattern\" : \"d/[a-f0-9]{12}\" , \"redaction\" : { \"method\" : \"hash\" } } }, \"applications\" : { \"$string\" : [ \"hash_device_id\" ] } }","title":"pattern"},{"location":"pii-config/types/#imei","text":"Matches an IMEI or IMEISV. { \"rules\" : { \"hash_imei\" : { \"type\" : \"imei\" , \"redaction\" : { \"method\" : \"hash\" } } }, \"applications\" : { \"$string\" : [ \"hash_imei\" ] } }","title":"imei"},{"location":"pii-config/types/#mac","text":"Matches a MAC address. { \"rules\" : { \"hash_mac\" : { \"type\" : \"mac\" , \"redaction\" : { \"method\" : \"hash\" } } }, \"applications\" : { \"$string\" : [ \"hash_mac\" ] } }","title":"mac"},{"location":"pii-config/types/#ip","text":"Matches any IP address. { \"rules\" : { \"hash_ip\" : { \"type\" : \"ip\" , \"redaction\" : { \"method\" : \"hash\" } } }, \"applications\" : { \"$string\" : [ \"hash_ip\" ] } }","title":"ip"},{"location":"pii-config/types/#creditcard","text":"Matches a creditcard number. { \"rules\" : { \"hash_cc\" : { \"type\" : \"creditcard\" , \"redaction\" : { \"method\" : \"hash\" } } }, \"applications\" : { \"$string\" : [ \"hash_cc\" ] } }","title":"creditcard"},{"location":"pii-config/types/#userpath","text":"Matches a local path (e.g. C:/Users/foo/ ). { \"rules\" : { \"hash_userpath\" : { \"type\" : \"userpath\" , \"redaction\" : { \"method\" : \"hash\" } } }, \"applications\" : { \"$string\" : [ \"hash_userpath\" ] } }","title":"userpath"},{"location":"pii-config/types/#anything","text":"Matches any value. This is basically equivalent to a wildcard regex. For example, to remove all strings: { \"rules\" : { \"remove_everything\" : { \"type\" : \"anything\" , \"redaction\" : { \"method\" : \"remove\" } } }, \"applications\" : { \"$string\" : [ \"remove_everything\" ] } }","title":"anything"},{"location":"pii-config/types/#multiple","text":"Combine multiple rules into one. This is a disjunction (OR): The field in question has to match only one of the rules to match the combined rule, not all of them. { \"rules\" : { \"remove_ips_and_macs\" : { \"type\" : \"multiple\" , \"rules\" : [ \"@ip\" , \"@mac\" ], \"hide_rule\" : false , // Hide the inner rules when showing which rules have been applied. Defaults to false. \"redaction\" : { \"method\" : \"remove\" } } }, \"applications\" : { \"$string\" : [ \"remove_ips_and_macs\" ] } }","title":"multiple"},{"location":"pii-config/types/#alias","text":"Alias one rule to the other. This is the same as multiple except that you can only wrap one rule. { \"rules\" : { \"remove_ips\" : { \"type\" : \"multiple\" , \"rule\" : \"@ip\" , \"hide_rule\" : false , // Hide the inner rule when showing which rules have been applied. Defaults to false. \"redaction\" : { \"method\" : \"remove\" } } }, \"applications\" : { \"$string\" : [ \"remove_ips\" ] } }","title":"alias"}]}